# [Lita is a chat bot written in Ruby](http://www.lita.io/)

Lita is a chat bot written in Ruby with persistent storage provided by Redis. It uses a plugin system to connect to different chat services and to provide new behavior. The plugin system uses the familiar tools of the Ruby ecosystem: RubyGems and Bundler.

# [WebSockets in Ruby](http://www.troikatech.com/blog/2014/02/26/websocket-webmachine)

```
App = Webmachine::Application do |app|
  app.configure do |config|
    config.adapter = :Reel
    config.adapter_options[:websocket_handler] = proc do |websocket|
      websocket << "hello, world"
    end
  end
end
```

```
class WebsocketHandler
  def call(websocket)
    loop do
      message = websocket.read
      # do something with the message, call methods on other objects, log stuff, have your fun
    end
  end
end
```

[webmachine-ruby](https://github.com/seancribbs/webmachine-ruby) makes it easy by allowing you to implement streaming APIs without much trouble, and I suppose it’ll only take a bit of JS to fallback from one to the other and provide an abstract connection to consumers.

# [Ruby Gotchas that will come back to haunt you](http://blog.elpassion.com/ruby-gotchas)

#### Use only `&&` / `||` operators

`and` / `or` operators have lower precedence than `&&` / `||`
`and` / `or` have lower precedence than `=`, while `&&` / `||` are of higher precedence
`and` / `or` have the same precedence, while `&&` has higher precedence than `||`

```
(surprise = true) and false # => surprise is true
surprise = (true && false)  # => surprise is false
```

#### Use only `==` operator

`==` / `===` / `eql?` / `equal?` are all different operators, meant for different situations.

#### Use `super` (no parantheses)

#### Inherit from `StandardError` (not Exception)

When you leave rescue statement empty, it means it will catch exceptions that inherit from StandardError, not Exception.

When you rescue Exception (which you should not), you’ll catch errors you won’t be able to recover from (like out of memory error). Also, you’ll catch system signals like SIGTERM, and in effect you won’t be able to terminate your script using CTRL-C.

#### Always use longer, more verbose version with classes wrapped by modules

`module` keyword (as well as `class` and `def`) will create new lexical scope for all the things you put inside.

`module Foo` creates the scope 'Foo', `class Bar`h creates new lexical scope (named 'Foo::Bar'), which has access to its parent scope ('Foo') and all constants declared in it.

`class Foo::Bar` creates another lexical scope, which is also named 'Foo::Bar', but here, it has no parent, and thus, no access to things from 'Foo' scope.

#### Never depend on built-in bang! methods return value

#### `attribute=(value)` always returns passed value

#### `private` will NOT make `self.method` private

You want `private_class_method :method_name` or `class << self`

# [Use An Ask, Don’t Tell Policy With Ruby](http://patshaughnessy.net/2014/2/10/use-an-ask-dont-tell-policy-with-ruby)

Naming methods is one of the most difficult and important things a programmer does. Picking a name for a method gives the reader a hint about what the method does, about what your intentions were when you wrote it.

Don’t imagine you are the computer. Don’t think about how to solve a problem by figuring out what Ruby should do and then writing down instructions for it to follow. Instead, start by asking Ruby for the answer.

> Objects encapsulate state. Don’t break that encapsulation.

When you send a message to an object, you should ask it for what you want, not tell it what to do or make assumptions about how it works internally.

# [Telling, Asking, and the Power of Jargon](http://pragdave.me/blog/2014/02/11/telling-asking-and-the-power-of-jargon/)

The idea of **Tell, Don’t Ask**, is that objects should take responsibility for their state, and should not allow other objects to bypass encapsulation and mess with the state.

Functional programming is about expressions. It’s about composition. It’s about transforming data, not storing it.

When programmers talk to programmers, they use jargon. By using jargon words (or terms of the trade, as the fancy folk call them), we communicate efficiently and effectively—we interact at a much deeper level. Each piece of jargon is a shortcut for a whole lot of shared experience, and by using jargon words, we root our conversation at a deeper level.

But jargon has to be protected. Consistently misuse a jargon word, and it loses its deeper meaning. It it no longer evocative—it’s just a noise. And if our jargon becomes diluted, then we as an industry become less efficient at communicating—we have to make explicit what was once tacit. Our talk becomes pedestrian and pedantic, mechanical rather than allusive. We lose the superpower of description.

# [Rails 4 Engines](http://tech.taskrabbit.com/blog/2014/02/11/rails-4-engines)

We have found that a [single app made up of several Rails engines](https://github.com/taskrabbit/rails_engines_example) strikes a great balance between the (initial) straightforwardness of the single Rails app and the modularity of the more service-oriented architecture.

Things got rough in coordinating across these apps. It wasn’t just the data access. We made APIs and allowed any app to have read-only access to the platform app’s database. This allowed things go much faster by preventing creation of many GET endpoints and possible points of failure. The main issue in coordinating releases that spanned apps. They just went slower than if it was one codebase. There was also interminable bumping of gem versions to get shared code to all the apps. Integration testing the whole experience was also very rough.

A single pull request has everything related to that feature. It rolls out atomically. Gems can be bumped once and our internal gems aren’t bumped at all as they live unbuilt in a gems folder in the app itself. We still get most of the modularization that multiple apps had. For example, the User model in the payments engine has all the stuff about balances and the one in the profile engine doesn’t know anything about all that and it’s various helper methods.

The issue with gem upgrades and odd server configurations does continue to exist in the engine model and is mostly fine in the many app model. The gem one is tough and we just try to stay on top of upgrading to the newest things and overall reducing dependencies. The specs will also run slower in the engine app, but you’ll have better integration testing.

The first engine we’ve recommend making to people is the admin engine. We started treating our hardworking admins like we should: a customer with their own needs and dedicated experience.

We don’t share layouts between our engines. We’ve made the choice to have all the frontend code in one engine and all of the other engines just serve API endpoints. There are several shared mixins for these backend engines, but they don’t need a layout because they are just using jbuilder to send back JSON to the frontend client. The frontend engine, therefore, doesn’t really use any models and has all the assets and such. Admin still has its own layout and uses a more traditional Rails MVC approach.

# [Using foreman and environment variables to isolate and run your apps in development](http://mauricio.github.io/2014/02/09/foreman-and-environment-variables.html)

```
rails: bundle exec rails s
postgres: postgres -D /Users/mauricio/databases/postgresql
elasticsearch: elasticsearch -f
```

```
alias fs="foreman start"
```

And foreman automatically loads the `.env` file that is at the same directory as your `Procfile`.

# [Installing and Building Docker With Ansible](http://blog.ansibleworks.com/2014/02/12/installing-and-building-docker-with-ansible)

```
ansible-galaxy install angstwad.docker_ubuntu
```

Use ansible-playbook inside a Docker file so we can write our complex automation in Ansible rather than a hodgepodge of docker commands and shell scripts.

```
FROM ubuntu
RUN apt-get -y update
RUN apt-get install -y python-yaml python-jinja2 git
RUN git clone http://github.com/ansible/ansible.git /tmp/ansible
WORKDIR /tmp/ansible
ENV PATH /tmp/ansible/bin:/sbin:/usr/sbin:/usr/bin
ENV ANSIBLE_LIBRARY /tmp/ansible/library
ENV PYTHONPATH /tmp/ansible/lib:$PYTHON_PATH
RUN git clone http://github.com/yourusername/yourrepo.git /tmp/example
ADD inventory /etc/ansible/hosts
WORKDIR /tmp/examples
RUN ansible-playbook site.yml -c local
EXPOSE 22 3000
ENTRYPOINT [“/usr/bin/foo”]
```

# [Ansible Vault allows keeping encrypted data in Playbooks](http://blog.ansibleworks.com/2014/02/19/ansible-vault/)

```
ansible-vault create vars.yml
ansible-vault edit vars.yml
ansible-playbook site.yml --ask-vault-pass
ansible-vault rekey vars.yml # change password
ansible-vault decrypt vars.yml # permanently decrypt
ansible-vault [encrypt|decrypt|rekey] vars1.yml vars2.yml vars3.yml
```

# [Ansible 1.5 Released](http://blog.ansibleworks.com/2014/02/28/ansible-1-5-released)

* Vault - a method of encrypting data in playbooks
* SSH pipelining
* implicit localhost
* play_hosts
* docker_image

# [postmodern/ruby-install](https://github.com/postmodern/ruby-install)

Does not require updating every time a new Ruby version comes out.
Does not require recipes for each individual Ruby version or configuration.
Does not support installing trunk/HEAD.

# [AdequateRecord Pro™: Like ActiveRecord, but more adequate](http://tenderlovemaking.com/2014/02/19/adequaterecord-pro-like-activerecord.html)

AdequateRecord Pro™ is a fork of ActiveRecord with some performance enhancements. In this post, I want to talk about how we achieved high performance in this branch. I hope you find these speed improvements to be “adequate”.

# [Gold Master Testing](http://blog.codeclimate.com/blog/2014/02/20/gold-master-testing/)

Rather than trying to specify all of the logical paths through an untested module, you can feed it a varied set of inputs and turn the outputs into automatically verifying tests. There’s no guarantee the outputs are correct in this case, but at least you can be sure they don’t change (which, in some systems is even more important).

1. Choose (or randomly generate, using a known seed) a set of inputs for your module or program.
2. Run the inputs through a known-good version of the system, persisting the output.
3. When testing a change, run the same inputs through the new version of the system and flag any output variation.
4. For each variation, have a human determine whether or not the change is expected and desirable. If it is, update the persisted gold master records.

# [The risks of feature branches and pre-merge code review](http://thepugautomatic.com/2014/02/code-review/)

Continuous delivery is about constantly deploying your code, facilitated by a pipeline: if some series of tests pass, the code is good to go. Ideally it deploys production automatically at the end of this pipeline.

Cycles are short and features are often released incrementally, perhaps using feature toggles.

This has major benefits. But if something clogs that pipeline, the benefits are reduced. And pre-merge code review clogs that pipeline.

> I always think that the longer a branch exists then the more work you are producing just to keep things integrated.

# [bbatsov/ruby-style-guide](https://github.com/bbatsov/ruby-style-guide)

# [Ruby Dependency Injection](http://theaudaciouscodeexperiment.com/blog/2013/10/18/ruby-dependency-injection/)

* Treat instantiating collaborators as a separate concern
* Remove this concern from your application’s core
* Pass in the instantiated object(s)

The key to getting the most out of DI is that all of your objects are instantiated for you somewhere else in the system. Objects can then concentrate on doing what they do rather than who they do it with and what their dependencies might be.

# [all the little things (rubyonales)](https://speakerdeck.com/skmetz/all-the-little-things-rubyonales)

Want better apps - make smaller things

Duplication is far cheaper than the wrong abstraction

Reach for open/closed

Small methods are simple

Small objects are simple

# [HM9000: Ready for Launch](http://blog.cloudfoundry.com/2014/02/22/hm9000-ready-for-launch/)

Cloud Foundry (CF) is a platform-as-a-service that, once deployed, makes it easy for developers to deploy, run and scale web applications. Powering this elegant PAAS is a complex distributed system comprised of several inter-operating components: the Cloud Controller (CC) accepts user input and directs Droplet Execution Agents (DEAs) to stage and run web applications. Meanwhile, the Router maps inbound traffic to web-app instances, while the Loggregator streams log output back to developers. All these components communicate via NATS, a performant message bus.

In terms of our simple mental model, HM’s job is easy to express:

* collect the desired state of the world (from the CC via HTTP)
* collect the actual state (from the DEAs via application heartbeats over NATS)
* perform a set diff to find discrepancies – e.g. missing apps or extra (rogue) apps
* send START and STOP messages to resolve these discrepancies

HM9000 solves the high-availability problem by relying on [etcd](https://github.com/coreos/etcd), a robust high-availability store distributed across multiple nodes. Individual HM9000 components are built to rely completely on the store for their knowledge of the world. This removes the need for maintaining in-memory information and allows clarifies the relationship between the various components (all data must flow through the store).

To avoid the singleton problem, we will turn on multiple instances of each HM9000 component across multiple nodes. These instances will vie for a lock in the high-availability store. The instance that grabs the lock gets to run and is responsible for maintaining the lock. Should that instance enter a bad state or die, the lock becomes available allowing another instance to pick up the slack. Since all state is stored in the store, the backup component should be able to function independently of the failed component.

Rather than communicate via messages the HM9000 components coordinate on data in etcd. The component that fetches desired state simply updates the desired state in the store. The component that listens for app heartbeats simply updates the actual state in the store. The analyzer performs the set diff by querying the actual state and desired state and placing decisions in the store. The sender sends START and STOP messages by simply acting on these decisions.

To ensure that HM9000′s various components use the same schema, we built a separate ORM-like library on top of the store. This allows the components to speak in terms of semantic models and abstracts away the details of the persistence layer. In a sense, this library forms the API by which components communicate. Having this separation was crucial – it helped us DRY up our code, and gave us one point of entry to change and version the persisted schema.

The power behind this data-centered approach is that it takes a time-domain problem (listening for heartbeats, polling for desired state, reacting to changes) and turns it into a data problem: instead of thinking in terms of responding to an app’s historical timeline it becomes possible to think in terms of operating on data sets of different configurations. Since keeping track of an app’s historical timeline was the root of much of the complexity of the original HM, this data-centered approach proved to be a great simplification for HM9000.

The mental model of timestamped decisions that are verified by the sender makes the problem domain easier to reason about, and the codebase cleaner. Moreover, it becomes much easier to unit and integration test the behavior of the system as the correct state can be set-up in the store and then evaluated.

Requiring that coordination be done via a data store allows us to build components that have no in-memory knowledge of the world. If a given component fails, another copy of the component can come up and take over its job — everything it needs to do its work is already in the store.

> Each component vies for a lock in etcd and maintains the lock as it does its work. Should the component fail, the lock is released and its doppelgänger can pick up where it left off.

# [Is Angular.js or Ember.js the better choice for Javascript frameworks?](http://www.quora.com/Client-side-MVC/Is-Angular-js-or-Ember-js-the-better-choice-for-Javascript-frameworks)

# [How to build a startup that learns quickly](https://medium.com/frameworks-ftw/fa74545c25a0)

#### If you’re not focused on the speed at which you learn, then you’re doing it wrong

```
revenue = money / time
information = money
revenue = information / time
```

The rate at which you gather information + make decisions serves as a proxy for the speed at which you’ll generate revenue. The faster you learn what works, the faster you’ll make money.

Reduce the amount time between someone on your team wondering how customers will use your product and knowing how they will use it.

[See and hear a 5-minute video of a real person using your site](http://peek.usertesting.com/)

Have every employee connect with customers in personal ways to distribute learning and get all team members thinking about how to solve problems.

# [Smart Guy Productivity Pitfalls](http://bookofhook.blogspot.de/2013/03/smart-guy-productivity-pitfalls.html)

An overinflated sense of your own abilities creates a constant state of production deficit, because you assume that you can make it up with a burst of brilliance and/or crunch.

1. Develop self-awareness
2. Give a shit
3. Minimize uncertainty
4. Commit to getting something done every day
5. Never say "I'll finish it up tomorrow" or "I'll make up for it by coming in early/staying late/working the weekend"
6. Do not overpromise to make up for poor productivity
7. Have an objective productivity metric
8. Accept that "the grind" is part of the job

# [Why Wesabe Lost to Mint](http://blog.precipice.org/why-wesabe-lost-to-mint/)

First, we chose not to work with Yodlee, but failed to find or make a replacement for them (until too late). We had some acquisition interest simply for the aggregator we’d built. We just didn’t build it nearly fast enough. That one mistake (not using or replacing Yodlee before Mint had a chance to launch on Yodlee) was probably enough to kill Wesabe alone.

Mint focused on making the user do almost no work at all, by automatically editing and categorizing their data, reducing the number of fields in their signup form, and giving them immediate gratification as soon as they possibly could; we completely sucked at all of that. Instead, I prioritized trying to build tools that would eventually help people change their financial behavior for the better, which I believed required people to more closely work with and understand their data. My goals may have been (okay, were) noble, but in the end we didn’t help the people I wanted to since the product failed. I was focused on trying to make the usability of editing data as easy and functional as it could be; Mint was focused on making it so you never had to do that at all. Their approach completely kicked our approach’s ass. (To be defensive for just a moment, their data accuracy – how well they automatically edited – was really low, and anyone who looked deeply into their data at Mint, especially in the beginning, was shocked at how inaccurate it was. The point, though, is hardly anyone seems to have looked.)

Not being dependent on a single source provider, preserving users’ privacy, helping users actually make positive change in their financial lives are great, rational reasons to pursue what we pursued. But none of them matter if the product is harder to use, since most people simply won’t care enough or get enough benefit from long-term features if a shorter-term alternative is available.

> A domain name doesn’t win you a market; launching second or fifth or tenth doesn’t lose you a market. You can’t blame your competitors or your board or the lack of or excess of investment.  Focus on what really matters: making users happy with your product as quickly as you can, and helping them as much as you can after that.  If you do those better than anyone else out there you’ll win.

# [colourco.de](http://colourco.de/)

# [CircuitBreaker](http://martinfowler.com/bliki/CircuitBreaker.html)

One of the big differences between in-memory calls and remote calls is that remote calls can fail, or hang without a response until some timeout limit is reached.

You wrap a protected function call in a circuit breaker object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all. Usually you'll also want some kind of monitor alert if the circuit breaker trips.

Since remote calls are often slow, it's often a good idea to put each call on a different thread using a future or promise to handle the results when they come back. By drawing these threads from a thread pool, you can arrange for the circuit to break when the thread pool is exhausted.

A common technique here is to put all requests on a queue, which the supplier consumes at its speed - a useful technique to avoid overloading servers. In this case the circuit breaks when the queue fills up.

[wsargent/circuit_breaker](https://github.com/wsargent/circuit_breaker/tree/master) - CircuitBreaker is a relatively simple Ruby mixin that will wrap a call to a given service in a circuit breaker pattern.

# [Fault Tolerance in a High Volume, Distributed System](http://techblog.netflix.com/2012/02/fault-tolerance-in-high-volume.html)

Some approaches to fallbacks we use are, in order of their impact on the user experience:

* **Cache**: Retrieve data from local or remote caches if the realtime dependency is unavailable, even if the data ends up being stale
* **Eventual Consistency**: Queue writes (such as in SQS) to be persisted once the dependency is available again
* **Stubbed Data**: Revert to default values when personalized options can't be retrieved
* **Empty Response**: Return a null or empty list which UIs can then ignore

# [Running Stripe CTF 2.0 on Mesos](http://karimson.com/posts/ctf-mesos/)

Mesos is a cluster manager that provides resource isolation and sharing across a cluster of machines. It can be thought of as an application scheduler for the data center. My idea was to leverage Mesos for scheduling and managing the levels. The problem is that Mesos provides a fairly low-level interface and does not have an out-of-the-box way of managing long-running applications. Luckily Mesosphere has released a solution in the form of Marathon.

Marathon is a Mesos framework for long-running services, and comes with a great Web UI and a REST interface for launching, scaling, and destroying applications. As soon as a participant needs a new level a request is made to Marathon that then handles the interaction with Mesos and makes sure that the level gets scheduled. Mesosphere has also open-sourced a way for Mesos to launch and interact with Docker.

HAProxy is a robust battle-tested load-balancer/proxy. Using Mesos means that I do not have direct control over which machine is running a particular container so HAProxy is used to redirect the user to the correct container regardless of where it is running.

# [Rails - the Missing Parts - Interactors](http://eng.joingrouper.com/blog/2014/03/03/rails-the-missing-parts-interactors)

The overwhelming trend in Rails codebases is for the majority of business logic to reside in very large God classes in the ActiveRecord /models directory. This is normally a clue that each class has too many responsibilities, a vast public API and methods that require the presence of a complex graph of associated objects in order to function at all.

Interactors demand that the core of your application should live in a set of plain-old-Ruby-objects (POROs) that are responsible for the main use-cases of your application, leaving your ActiveRecord classes as skinny interfaces to your data-store. By looking at the names of your Interactors, you should be able to tell what your application does; SignUp, BookGrouper, AssignBarForGrouper, etc. Classes like Member and Bar just validate and store attributes like name, location and date.

#### [HN](https://news.ycombinator.com/item?id=7335211)

The key point for an "interactor" extraction is when you have multiple models being created in symphony, like a Signup model. Or if you for some reason need to reuse the behavior. But if all your controllers look like this, with one "interactor" model per action, you're doing it wrong.

One way to spend hundreds of thousands of LOC on an application is to stuff it with needless abstractions. That doesn't make it "advanced", and it's not Rails that's falling over, it's probably just some shitty code.

It's certainly a red herring that you need to teach your abstractions to new developers and that it's an endeavor to do so.

Build the abstraction when you actually need it, not when you think you're going to need it, or pretty close to needing it, etc. Because 98% of the time, YAGNI.

# [Microservices](http://martinfowler.com/articles/microservices.html)

Monolith - a single logical executable. Any changes to the system involve building and deploying a new version of the server-side application.

> A component is a unit of software that is independently replaceable and upgradeable.

Libraries are components that are linked into a program and called using in-memory function calls, while services are out-of-process components that communicate with a mechanism such as a web service request, or remote procedure call.

One main reason for using services as components (rather than libraries) is that services are independently deployable.

Remote calls are more expensive than in-process calls, and thus remote APIs need to be coarser-grained, which is often more awkward to use. If you need to change the allocation of responsibilities between components, such movements of behavior are harder to do when you're crossing process boundaries.

Microservice proponents prefer the notion that a team should own a product over its full lifetime. A common inspiration for this is Amazon's notion of "you build, you run it" where a development team takes full responsibility for the software in production. 

The product mentality, ties in with the linkage to business capabilities. Rather than looking at the software as a set of functionality to be completed, there is an on-going relationship where the question is how can software assist its users to enhance the business capability.

> Smart endpoints and dumb pipes

The biggest issue in changing a monolith into microservices lies in changing the communication pattern. A naive conversion from in-memory method calls to RPC leads to chatty communications which don't perform well. Instead you need to replace the fine-graining communication with a coarser-grained approach.

DDD divides a complex domain up into multiple bounded contexts and maps out the relationships between them.

Often businesses handle a degree of inconsistency in order to respond quickly to demand, while having some kind of reversal process to deal with mistakes. The trade-off is worth it as long as the cost of fixing mistakes is less than the cost of lost business under greater consistency.

| Environment | Tests |
|-|-|
| Build | Unit, Functional & Acceptance |
| Integration | Integration tests |
| UAT | User acceptance tests |
| Performance | performance tests |

A consequence of using services as components, is that applications need to be designed so that they can tolerate the failure of services. Microservice teams constantly reflect on how service failures affect the user experience.

Since services can fail at any time, it's important to be able to detect the failures quickly and, if possible, automatically restore service. Microservice applications put a lot of emphasis on real-time monitoring of the application, checking both architectural elements (how many requests per second is the database getting) and business relevant metrics (such as how many orders per minute are received).

Microservice teams would expect to see sophisticated monitoring and logging setups for each individual service such as dashboards showing up/down status and a variety of operational and business relevant metrics. Details on circuit breaker status, current throughput and latency are other examples we often encounter in the wild.

# [The Best PR Advice You’ve Never Heard](http://firstround.com/article/The-Best-PR-Advice-Youve-Never-Heard-from-Facebooks-Head-of-Tech-Communications)

#### Relevant.

Who is your audience, and is your company solving a problem that they care about? What matters to them about that problem? Why does your solution deserve attention? Fight for greater relevance. Make it a priority in your positioning.

#### Inevitable.

You want people to feel that whatever you’re developing is inevitable. This is like having a gust of wind at your company’s back.  If it doesn’t seem like whatever trend or movement you’re a part of will eventually come to pass, you’ll be fighting against the wind.

#### Believable.

Being believable isn't just convincing people you can win, it's convincing them that they want you to win.

#### Simple.

People are torn in so many directions these days — they’re on Facebook, checking email, trying to balance work and friends and family. Somehow you have to break through, and the way to do this is to keep things simple.

> What is the one line you want people to remember? You only get one.

You need that long-term vision that inspires people. But if you don’t make things happen in the short-term, no one is going to care.

> Launching is like the opening move in a chess game. It doesn't mean that much.

You should only launch if you already know what your second move is going to be. This is a journey, and you need to be continuously putting points on the board. To do that, you have to know where you’re going next. This is what will elevate whatever you’re doing in the short term to the next level. And the more short-term points you rack up, the more believable the long-term message becomes.

You have such limited resources at the beginning and everyone is telling you that you have to do different things. What really belongs at the top of your list?

#### Brand lens

```
In Action
    Differentiators
       Attributes
            Tagline
```

**TAGLINE**: for Google, it’s to organize all of the world’s information. For Facebook, it’s giving people the power to share and make the world more open and connected.

**ATTRIBUTES**: at Google, one of the key adjectives seems to be “fun” — easily observed in the colorful, whimsical feel of its offices. At Facebook, it's moving fast, constantly evolving.

**DIFFERENTIATORS**: these are the things that set you apart from the other companies out there in the space.

**ACTION**: whatever it is you think you want to do, run it through your brand lens. See if it highlights the words that you’ve chosen that are meaningful to you and that set you apart. If the answer is no, don’t do it. If the answer is yes, then you have to do it.

Taking action is also about separating internal priorities from external priorities. Inside the company, people are working on a lot of diverse projects, but not everything deserves the spotlight.

> Focus your external marketing on where you want to go as a company, where you have to go to succeed, or what inspires your customers most. It might not be what you are building today.

Figure out who you are as a founder, as a leader, as a brand. And whatever you are, be the best at it.

Don’t try to be all things to all people. It’s ugly and impossible.

A lot of money can make you very stupid — especially early on. A lot of attention can make you stupid. It can make you do a lot of things that aren’t the right things. Focus on what you need to do, not just what you can do because you have the resources.

Don’t be lazy. Don’t launch at a conference. You can use conferences to continue to get your product out there and talk about it, but actually launching at one is pure laziness. Don’t use buzzwords. People don’t read them. They sound like white noise.

Don’t get into fights with people or other brands.

The more you keep your eyes fixed on competitors, the less you’re doing to build your own company.

You are never as good or as bad as the press says you are, so don’t buy into it too much.

As a founder, you know more about your topic than anyone in the world.

The best CEOs I have ever worked for are tremendous listeners. Take everything as a listening opportunity.

Be very conscious of the company you keep

You know you have deeply resonant messaging when it only gains meaning as time passes. Make sure as weeks and years pass, your message is only getting sharper, clearer, more impactful.

# [Coconut Headphones: Why Agile Has Failed](http://mikehadlow.blogspot.co.uk/2014/03/coconut-headphones-why-agile-has-failed.html)

Because creating good software is so much about technical decisions and so little about management process, I believe that there is very little place for non-technical managers in any software development organisation. If your role is simply asking for estimates and enforcing the agile rituals: stand-ups, fortnightly sprints, retrospectives; then you are an impediment rather than an asset to delivery.

* The skills and talents of individual programmers are the main determinant of software quality. No amount of management, methodology, or high-level architecture astronautism can compensate for a poor quality team.
* The motivation and empowerment of programmers has a direct and strong relationship to the quality of  the software.
* Hard deadlines, especially micro-deadlines will result in poor quality software that will take longer to deliver.
* The consequences of poor design decisions multiply rapidly.
* It will usually take multiple attempts to arrive at a viable design.
* You should make it easy to throw away code and start again.
* Latency kills. Short feedback loops to measurable outcomes create good software.
* Estimates are guess-timates; they are mostly useless. There is a geometric relationship between the length of an estimate and its inaccuracy.
* Software does not scale. Software teams do not scale.
* Architecture should be as much about enabling small teams to work on small components as the technical requirements of the software.

# [Ansible provisioning of a Galera Cluster (Percona XtraDB Cluster)](http://patg.net/docker/2014/03/03/ansible.html)

# [Dockerfile Best Practices - take 2](http://crosbymichael.com/dockerfile-best-practices-take-2.html)

#### Don't boot init

The goal is that you only run one process per container so an init or supervisor is not needed. You don't need the added overhead of init or a supervisor. if the processes dies inside a container then the container dies, instead of restarting the process just restart the same container or a new container.

#### Don't upgrade in builds

Best case you run an upgrade in a build and it works. Worst case a pkg tries to mount, etc and it fails. You should bake security fixes into the base images and rebuild on top of them so that the end result is consistent.

3. Use small base images (eg `debian:jessie`)
4. Use specific tags
5. Group common operations
6. Use your own base images

# [The Relationship Between Hours Worked and Productivity](http://cs.stanford.edu/people/eroberts/cs201/projects/crunchmode/econ-hours-productivity.html)

This effectively means that productivity during 60 hour weeks would be less than two-thirds that of what it was when 40 hour weeks were worked.

Thus, overworked employees may simply be substantially less productive at all hours of the work day, enough so that their average productivity decreases to the extent the additional hours they are working provide no benefit (and, in fact, are detrimental). Sleep deprivation and sustained reduced sleep is known to negatively impact productivity at all hours of the day.