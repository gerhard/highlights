# [Lita is a chat bot written in Ruby](http://www.lita.io/)

Lita is a chat bot written in Ruby with persistent storage provided by Redis. It uses a plugin system to connect to different chat services and to provide new behavior. The plugin system uses the familiar tools of the Ruby ecosystem: RubyGems and Bundler.

# [WebSockets in Ruby](http://www.troikatech.com/blog/2014/02/26/websocket-webmachine)

```
App = Webmachine::Application do |app|
  app.configure do |config|
    config.adapter = :Reel
    config.adapter_options[:websocket_handler] = proc do |websocket|
      websocket << "hello, world"
    end
  end
end
```

```
class WebsocketHandler
  def call(websocket)
    loop do
      message = websocket.read
      # do something with the message, call methods on other objects, log stuff, have your fun
    end
  end
end
```

[webmachine-ruby](https://github.com/seancribbs/webmachine-ruby) makes it easy by allowing you to implement streaming APIs without much trouble, and I suppose it’ll only take a bit of JS to fallback from one to the other and provide an abstract connection to consumers.

# [Ruby Gotchas that will come back to haunt you](http://blog.elpassion.com/ruby-gotchas)

#### Use only `&&` / `||` operators

`and` / `or` operators have lower precedence than `&&` / `||`
`and` / `or` have lower precedence than `=`, while `&&` / `||` are of higher precedence
`and` / `or` have the same precedence, while `&&` has higher precedence than `||`

```
(surprise = true) and false # => surprise is true
surprise = (true && false)  # => surprise is false
```

#### Use only `==` operator

`==` / `===` / `eql?` / `equal?` are all different operators, meant for different situations.

#### Use `super` (no parantheses)

#### Inherit from `StandardError` (not Exception)

When you leave rescue statement empty, it means it will catch exceptions that inherit from StandardError, not Exception.

When you rescue Exception (which you should not), you’ll catch errors you won’t be able to recover from (like out of memory error). Also, you’ll catch system signals like SIGTERM, and in effect you won’t be able to terminate your script using CTRL-C.

#### Always use longer, more verbose version with classes wrapped by modules

`module` keyword (as well as `class` and `def`) will create new lexical scope for all the things you put inside.

`module Foo` creates the scope 'Foo', `class Bar`h creates new lexical scope (named 'Foo::Bar'), which has access to its parent scope ('Foo') and all constants declared in it.

`class Foo::Bar` creates another lexical scope, which is also named 'Foo::Bar', but here, it has no parent, and thus, no access to things from 'Foo' scope.

#### Never depend on built-in bang! methods return value

#### `attribute=(value)` always returns passed value

#### `private` will NOT make `self.method` private

You want `private_class_method :method_name` or `class << self`

# [Use An Ask, Don’t Tell Policy With Ruby](http://patshaughnessy.net/2014/2/10/use-an-ask-dont-tell-policy-with-ruby)

Naming methods is one of the most difficult and important things a programmer does. Picking a name for a method gives the reader a hint about what the method does, about what your intentions were when you wrote it.

Don’t imagine you are the computer. Don’t think about how to solve a problem by figuring out what Ruby should do and then writing down instructions for it to follow. Instead, start by asking Ruby for the answer.

> Objects encapsulate state. Don’t break that encapsulation.

When you send a message to an object, you should ask it for what you want, not tell it what to do or make assumptions about how it works internally.

# [Telling, Asking, and the Power of Jargon](http://pragdave.me/blog/2014/02/11/telling-asking-and-the-power-of-jargon/)

The idea of **Tell, Don’t Ask**, is that objects should take responsibility for their state, and should not allow other objects to bypass encapsulation and mess with the state.

Functional programming is about expressions. It’s about composition. It’s about transforming data, not storing it.

When programmers talk to programmers, they use jargon. By using jargon words (or terms of the trade, as the fancy folk call them), we communicate efficiently and effectively—we interact at a much deeper level. Each piece of jargon is a shortcut for a whole lot of shared experience, and by using jargon words, we root our conversation at a deeper level.

But jargon has to be protected. Consistently misuse a jargon word, and it loses its deeper meaning. It it no longer evocative—it’s just a noise. And if our jargon becomes diluted, then we as an industry become less efficient at communicating—we have to make explicit what was once tacit. Our talk becomes pedestrian and pedantic, mechanical rather than allusive. We lose the superpower of description.

# [Rails 4 Engines](http://tech.taskrabbit.com/blog/2014/02/11/rails-4-engines)

We have found that a [single app made up of several Rails engines](https://github.com/taskrabbit/rails_engines_example) strikes a great balance between the (initial) straightforwardness of the single Rails app and the modularity of the more service-oriented architecture.

Things got rough in coordinating across these apps. It wasn’t just the data access. We made APIs and allowed any app to have read-only access to the platform app’s database. This allowed things go much faster by preventing creation of many GET endpoints and possible points of failure. The main issue in coordinating releases that spanned apps. They just went slower than if it was one codebase. There was also interminable bumping of gem versions to get shared code to all the apps. Integration testing the whole experience was also very rough.

A single pull request has everything related to that feature. It rolls out atomically. Gems can be bumped once and our internal gems aren’t bumped at all as they live unbuilt in a gems folder in the app itself. We still get most of the modularization that multiple apps had. For example, the User model in the payments engine has all the stuff about balances and the one in the profile engine doesn’t know anything about all that and it’s various helper methods.

The issue with gem upgrades and odd server configurations does continue to exist in the engine model and is mostly fine in the many app model. The gem one is tough and we just try to stay on top of upgrading to the newest things and overall reducing dependencies. The specs will also run slower in the engine app, but you’ll have better integration testing.

The first engine we’ve recommend making to people is the admin engine. We started treating our hardworking admins like we should: a customer with their own needs and dedicated experience.

We don’t share layouts between our engines. We’ve made the choice to have all the frontend code in one engine and all of the other engines just serve API endpoints. There are several shared mixins for these backend engines, but they don’t need a layout because they are just using jbuilder to send back JSON to the frontend client. The frontend engine, therefore, doesn’t really use any models and has all the assets and such. Admin still has its own layout and uses a more traditional Rails MVC approach.

# [Using foreman and environment variables to isolate and run your apps in development](http://mauricio.github.io/2014/02/09/foreman-and-environment-variables.html)

```
rails: bundle exec rails s
postgres: postgres -D /Users/mauricio/databases/postgresql
elasticsearch: elasticsearch -f
```

```
alias fs="foreman start"
```

And foreman automatically loads the `.env` file that is at the same directory as your `Procfile`.

# [Installing and Building Docker With Ansible](http://blog.ansibleworks.com/2014/02/12/installing-and-building-docker-with-ansible)

```
ansible-galaxy install angstwad.docker_ubuntu
```

Use ansible-playbook inside a Docker file so we can write our complex automation in Ansible rather than a hodgepodge of docker commands and shell scripts.

```
FROM ubuntu
RUN apt-get -y update
RUN apt-get install -y python-yaml python-jinja2 git
RUN git clone http://github.com/ansible/ansible.git /tmp/ansible
WORKDIR /tmp/ansible
ENV PATH /tmp/ansible/bin:/sbin:/usr/sbin:/usr/bin
ENV ANSIBLE_LIBRARY /tmp/ansible/library
ENV PYTHONPATH /tmp/ansible/lib:$PYTHON_PATH
RUN git clone http://github.com/yourusername/yourrepo.git /tmp/example
ADD inventory /etc/ansible/hosts
WORKDIR /tmp/examples
RUN ansible-playbook site.yml -c local
EXPOSE 22 3000
ENTRYPOINT [“/usr/bin/foo”]
```

# [Ansible Vault allows keeping encrypted data in Playbooks](http://blog.ansibleworks.com/2014/02/19/ansible-vault/)

```
ansible-vault create vars.yml
ansible-vault edit vars.yml
ansible-playbook site.yml --ask-vault-pass
ansible-vault rekey vars.yml # change password
ansible-vault decrypt vars.yml # permanently decrypt
ansible-vault [encrypt|decrypt|rekey] vars1.yml vars2.yml vars3.yml
```

# [Ansible 1.5 Released](http://blog.ansibleworks.com/2014/02/28/ansible-1-5-released)

* Vault - a method of encrypting data in playbooks
* SSH pipelining
* implicit localhost
* play_hosts
* docker_image

# [postmodern/ruby-install](https://github.com/postmodern/ruby-install)

Does not require updating every time a new Ruby version comes out.
Does not require recipes for each individual Ruby version or configuration.
Does not support installing trunk/HEAD.

# [AdequateRecord Pro™: Like ActiveRecord, but more adequate](http://tenderlovemaking.com/2014/02/19/adequaterecord-pro-like-activerecord.html)

AdequateRecord Pro™ is a fork of ActiveRecord with some performance enhancements. In this post, I want to talk about how we achieved high performance in this branch. I hope you find these speed improvements to be “adequate”.

# [Gold Master Testing](http://blog.codeclimate.com/blog/2014/02/20/gold-master-testing/)

Rather than trying to specify all of the logical paths through an untested module, you can feed it a varied set of inputs and turn the outputs into automatically verifying tests. There’s no guarantee the outputs are correct in this case, but at least you can be sure they don’t change (which, in some systems is even more important).

1. Choose (or randomly generate, using a known seed) a set of inputs for your module or program.
2. Run the inputs through a known-good version of the system, persisting the output.
3. When testing a change, run the same inputs through the new version of the system and flag any output variation.
4. For each variation, have a human determine whether or not the change is expected and desirable. If it is, update the persisted gold master records.

# [The risks of feature branches and pre-merge code review](http://thepugautomatic.com/2014/02/code-review/)

Continuous delivery is about constantly deploying your code, facilitated by a pipeline: if some series of tests pass, the code is good to go. Ideally it deploys production automatically at the end of this pipeline.

Cycles are short and features are often released incrementally, perhaps using feature toggles.

This has major benefits. But if something clogs that pipeline, the benefits are reduced. And pre-merge code review clogs that pipeline.

> I always think that the longer a branch exists then the more work you are producing just to keep things integrated.

# [bbatsov/ruby-style-guide](https://github.com/bbatsov/ruby-style-guide)

# [Ruby Dependency Injection](http://theaudaciouscodeexperiment.com/blog/2013/10/18/ruby-dependency-injection/)

* Treat instantiating collaborators as a separate concern
* Remove this concern from your application’s core
* Pass in the instantiated object(s)

The key to getting the most out of DI is that all of your objects are instantiated for you somewhere else in the system. Objects can then concentrate on doing what they do rather than who they do it with and what their dependencies might be.

# [all the little things (rubyonales)](https://speakerdeck.com/skmetz/all-the-little-things-rubyonales)

Want better apps - make smaller things

Duplication is far cheaper than the wrong abstraction

Reach for open/closed

Small methods are simple

Small objects are simple

# [HM9000: Ready for Launch](http://blog.cloudfoundry.com/2014/02/22/hm9000-ready-for-launch/)

Cloud Foundry (CF) is a platform-as-a-service that, once deployed, makes it easy for developers to deploy, run and scale web applications. Powering this elegant PAAS is a complex distributed system comprised of several inter-operating components: the Cloud Controller (CC) accepts user input and directs Droplet Execution Agents (DEAs) to stage and run web applications. Meanwhile, the Router maps inbound traffic to web-app instances, while the Loggregator streams log output back to developers. All these components communicate via NATS, a performant message bus.

In terms of our simple mental model, HM’s job is easy to express:

* collect the desired state of the world (from the CC via HTTP)
* collect the actual state (from the DEAs via application heartbeats over NATS)
* perform a set diff to find discrepancies – e.g. missing apps or extra (rogue) apps
* send START and STOP messages to resolve these discrepancies

HM9000 solves the high-availability problem by relying on [etcd](https://github.com/coreos/etcd), a robust high-availability store distributed across multiple nodes. Individual HM9000 components are built to rely completely on the store for their knowledge of the world. This removes the need for maintaining in-memory information and allows clarifies the relationship between the various components (all data must flow through the store).

To avoid the singleton problem, we will turn on multiple instances of each HM9000 component across multiple nodes. These instances will vie for a lock in the high-availability store. The instance that grabs the lock gets to run and is responsible for maintaining the lock. Should that instance enter a bad state or die, the lock becomes available allowing another instance to pick up the slack. Since all state is stored in the store, the backup component should be able to function independently of the failed component.

Rather than communicate via messages the HM9000 components coordinate on data in etcd. The component that fetches desired state simply updates the desired state in the store. The component that listens for app heartbeats simply updates the actual state in the store. The analyzer performs the set diff by querying the actual state and desired state and placing decisions in the store. The sender sends START and STOP messages by simply acting on these decisions.

To ensure that HM9000′s various components use the same schema, we built a separate ORM-like library on top of the store. This allows the components to speak in terms of semantic models and abstracts away the details of the persistence layer. In a sense, this library forms the API by which components communicate. Having this separation was crucial – it helped us DRY up our code, and gave us one point of entry to change and version the persisted schema.

The power behind this data-centered approach is that it takes a time-domain problem (listening for heartbeats, polling for desired state, reacting to changes) and turns it into a data problem: instead of thinking in terms of responding to an app’s historical timeline it becomes possible to think in terms of operating on data sets of different configurations. Since keeping track of an app’s historical timeline was the root of much of the complexity of the original HM, this data-centered approach proved to be a great simplification for HM9000.

The mental model of timestamped decisions that are verified by the sender makes the problem domain easier to reason about, and the codebase cleaner. Moreover, it becomes much easier to unit and integration test the behavior of the system as the correct state can be set-up in the store and then evaluated.

Requiring that coordination be done via a data store allows us to build components that have no in-memory knowledge of the world. If a given component fails, another copy of the component can come up and take over its job — everything it needs to do its work is already in the store.

> Each component vies for a lock in etcd and maintains the lock as it does its work. Should the component fail, the lock is released and its doppelgänger can pick up where it left off.

# [Is Angular.js or Ember.js the better choice for Javascript frameworks?](http://www.quora.com/Client-side-MVC/Is-Angular-js-or-Ember-js-the-better-choice-for-Javascript-frameworks)

# [How to build a startup that learns quickly](https://medium.com/frameworks-ftw/fa74545c25a0)

#### If you’re not focused on the speed at which you learn, then you’re doing it wrong

```
revenue = money / time
information = money
revenue = information / time
```

The rate at which you gather information + make decisions serves as a proxy for the speed at which you’ll generate revenue. The faster you learn what works, the faster you’ll make money.

Reduce the amount time between someone on your team wondering how customers will use your product and knowing how they will use it.

[See and hear a 5-minute video of a real person using your site](http://peek.usertesting.com/)

Have every employee connect with customers in personal ways to distribute learning and get all team members thinking about how to solve problems.

# [Smart Guy Productivity Pitfalls](http://bookofhook.blogspot.de/2013/03/smart-guy-productivity-pitfalls.html)

An overinflated sense of your own abilities creates a constant state of production deficit, because you assume that you can make it up with a burst of brilliance and/or crunch.

1. Develop self-awareness
2. Give a shit
3. Minimize uncertainty
4. Commit to getting something done every day
5. Never say "I'll finish it up tomorrow" or "I'll make up for it by coming in early/staying late/working the weekend"
6. Do not overpromise to make up for poor productivity
7. Have an objective productivity metric
8. Accept that "the grind" is part of the job

# [Why Wesabe Lost to Mint](http://blog.precipice.org/why-wesabe-lost-to-mint/)

First, we chose not to work with Yodlee, but failed to find or make a replacement for them (until too late). We had some acquisition interest simply for the aggregator we’d built. We just didn’t build it nearly fast enough. That one mistake (not using or replacing Yodlee before Mint had a chance to launch on Yodlee) was probably enough to kill Wesabe alone.

Mint focused on making the user do almost no work at all, by automatically editing and categorizing their data, reducing the number of fields in their signup form, and giving them immediate gratification as soon as they possibly could; we completely sucked at all of that. Instead, I prioritized trying to build tools that would eventually help people change their financial behavior for the better, which I believed required people to more closely work with and understand their data. My goals may have been (okay, were) noble, but in the end we didn’t help the people I wanted to since the product failed. I was focused on trying to make the usability of editing data as easy and functional as it could be; Mint was focused on making it so you never had to do that at all. Their approach completely kicked our approach’s ass. (To be defensive for just a moment, their data accuracy – how well they automatically edited – was really low, and anyone who looked deeply into their data at Mint, especially in the beginning, was shocked at how inaccurate it was. The point, though, is hardly anyone seems to have looked.)

Not being dependent on a single source provider, preserving users’ privacy, helping users actually make positive change in their financial lives are great, rational reasons to pursue what we pursued. But none of them matter if the product is harder to use, since most people simply won’t care enough or get enough benefit from long-term features if a shorter-term alternative is available.

> A domain name doesn’t win you a market; launching second or fifth or tenth doesn’t lose you a market. You can’t blame your competitors or your board or the lack of or excess of investment.  Focus on what really matters: making users happy with your product as quickly as you can, and helping them as much as you can after that.  If you do those better than anyone else out there you’ll win.

# [colourco.de](http://colourco.de/)

# [CircuitBreaker](http://martinfowler.com/bliki/CircuitBreaker.html)

One of the big differences between in-memory calls and remote calls is that remote calls can fail, or hang without a response until some timeout limit is reached.

You wrap a protected function call in a circuit breaker object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all. Usually you'll also want some kind of monitor alert if the circuit breaker trips.

Since remote calls are often slow, it's often a good idea to put each call on a different thread using a future or promise to handle the results when they come back. By drawing these threads from a thread pool, you can arrange for the circuit to break when the thread pool is exhausted.

A common technique here is to put all requests on a queue, which the supplier consumes at its speed - a useful technique to avoid overloading servers. In this case the circuit breaks when the queue fills up.

[wsargent/circuit_breaker](https://github.com/wsargent/circuit_breaker/tree/master) - CircuitBreaker is a relatively simple Ruby mixin that will wrap a call to a given service in a circuit breaker pattern.

# [Fault Tolerance in a High Volume, Distributed System](http://techblog.netflix.com/2012/02/fault-tolerance-in-high-volume.html)

Some approaches to fallbacks we use are, in order of their impact on the user experience:

* **Cache**: Retrieve data from local or remote caches if the realtime dependency is unavailable, even if the data ends up being stale
* **Eventual Consistency**: Queue writes (such as in SQS) to be persisted once the dependency is available again
* **Stubbed Data**: Revert to default values when personalized options can't be retrieved
* **Empty Response**: Return a null or empty list which UIs can then ignore

# [Running Stripe CTF 2.0 on Mesos](http://karimson.com/posts/ctf-mesos/)

Mesos is a cluster manager that provides resource isolation and sharing across a cluster of machines. It can be thought of as an application scheduler for the data center. My idea was to leverage Mesos for scheduling and managing the levels. The problem is that Mesos provides a fairly low-level interface and does not have an out-of-the-box way of managing long-running applications. Luckily Mesosphere has released a solution in the form of Marathon.

Marathon is a Mesos framework for long-running services, and comes with a great Web UI and a REST interface for launching, scaling, and destroying applications. As soon as a participant needs a new level a request is made to Marathon that then handles the interaction with Mesos and makes sure that the level gets scheduled. Mesosphere has also open-sourced a way for Mesos to launch and interact with Docker.

HAProxy is a robust battle-tested load-balancer/proxy. Using Mesos means that I do not have direct control over which machine is running a particular container so HAProxy is used to redirect the user to the correct container regardless of where it is running.

# [Rails - the Missing Parts - Interactors](http://eng.joingrouper.com/blog/2014/03/03/rails-the-missing-parts-interactors)

The overwhelming trend in Rails codebases is for the majority of business logic to reside in very large God classes in the ActiveRecord /models directory. This is normally a clue that each class has too many responsibilities, a vast public API and methods that require the presence of a complex graph of associated objects in order to function at all.

Interactors demand that the core of your application should live in a set of plain-old-Ruby-objects (POROs) that are responsible for the main use-cases of your application, leaving your ActiveRecord classes as skinny interfaces to your data-store. By looking at the names of your Interactors, you should be able to tell what your application does; SignUp, BookGrouper, AssignBarForGrouper, etc. Classes like Member and Bar just validate and store attributes like name, location and date.

#### [HN](https://news.ycombinator.com/item?id=7335211)

The key point for an "interactor" extraction is when you have multiple models being created in symphony, like a Signup model. Or if you for some reason need to reuse the behavior. But if all your controllers look like this, with one "interactor" model per action, you're doing it wrong.

One way to spend hundreds of thousands of LOC on an application is to stuff it with needless abstractions. That doesn't make it "advanced", and it's not Rails that's falling over, it's probably just some shitty code.

It's certainly a red herring that you need to teach your abstractions to new developers and that it's an endeavor to do so.

Build the abstraction when you actually need it, not when you think you're going to need it, or pretty close to needing it, etc. Because 98% of the time, YAGNI.