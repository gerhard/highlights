# [Lita is a chat bot written in Ruby](http://www.lita.io/)

Lita is a chat bot written in Ruby with persistent storage provided by Redis. It uses a plugin system to connect to different chat services and to provide new behavior. The plugin system uses the familiar tools of the Ruby ecosystem: RubyGems and Bundler.

# [WebSockets in Ruby](http://www.troikatech.com/blog/2014/02/26/websocket-webmachine)

```
App = Webmachine::Application do |app|
  app.configure do |config|
    config.adapter = :Reel
    config.adapter_options[:websocket_handler] = proc do |websocket|
      websocket << "hello, world"
    end
  end
end
```

```
class WebsocketHandler
  def call(websocket)
    loop do
      message = websocket.read
      # do something with the message, call methods on other objects, log stuff, have your fun
    end
  end
end
```

[webmachine-ruby](https://github.com/seancribbs/webmachine-ruby) makes it easy by allowing you to implement streaming APIs without much trouble, and I suppose it’ll only take a bit of JS to fallback from one to the other and provide an abstract connection to consumers.

# [Ruby Gotchas that will come back to haunt you](http://blog.elpassion.com/ruby-gotchas)

#### Use only `&&` / `||` operators

`and` / `or` operators have lower precedence than `&&` / `||`
`and` / `or` have lower precedence than `=`, while `&&` / `||` are of higher precedence
`and` / `or` have the same precedence, while `&&` has higher precedence than `||`

```
(surprise = true) and false # => surprise is true
surprise = (true && false)  # => surprise is false
```

#### Use only `==` operator

`==` / `===` / `eql?` / `equal?` are all different operators, meant for different situations.

#### Use `super` (no parantheses)

#### Inherit from `StandardError` (not Exception)

When you leave rescue statement empty, it means it will catch exceptions that inherit from StandardError, not Exception.

When you rescue Exception (which you should not), you’ll catch errors you won’t be able to recover from (like out of memory error). Also, you’ll catch system signals like SIGTERM, and in effect you won’t be able to terminate your script using CTRL-C.

#### Always use longer, more verbose version with classes wrapped by modules

`module` keyword (as well as `class` and `def`) will create new lexical scope for all the things you put inside.

`module Foo` creates the scope 'Foo', `class Bar`h creates new lexical scope (named 'Foo::Bar'), which has access to its parent scope ('Foo') and all constants declared in it.

`class Foo::Bar` creates another lexical scope, which is also named 'Foo::Bar', but here, it has no parent, and thus, no access to things from 'Foo' scope.

#### Never depend on built-in bang! methods return value

#### `attribute=(value)` always returns passed value

#### `private` will NOT make `self.method` private

You want `private_class_method :method_name` or `class << self`

# [Use An Ask, Don’t Tell Policy With Ruby](http://patshaughnessy.net/2014/2/10/use-an-ask-dont-tell-policy-with-ruby)

Naming methods is one of the most difficult and important things a programmer does. Picking a name for a method gives the reader a hint about what the method does, about what your intentions were when you wrote it.

Don’t imagine you are the computer. Don’t think about how to solve a problem by figuring out what Ruby should do and then writing down instructions for it to follow. Instead, start by asking Ruby for the answer.

> Objects encapsulate state. Don’t break that encapsulation.

When you send a message to an object, you should ask it for what you want, not tell it what to do or make assumptions about how it works internally.

# [Telling, Asking, and the Power of Jargon](http://pragdave.me/blog/2014/02/11/telling-asking-and-the-power-of-jargon/)

The idea of **Tell, Don’t Ask**, is that objects should take responsibility for their state, and should not allow other objects to bypass encapsulation and mess with the state.

Functional programming is about expressions. It’s about composition. It’s about transforming data, not storing it.

When programmers talk to programmers, they use jargon. By using jargon words (or terms of the trade, as the fancy folk call them), we communicate efficiently and effectively—we interact at a much deeper level. Each piece of jargon is a shortcut for a whole lot of shared experience, and by using jargon words, we root our conversation at a deeper level.

But jargon has to be protected. Consistently misuse a jargon word, and it loses its deeper meaning. It it no longer evocative—it’s just a noise. And if our jargon becomes diluted, then we as an industry become less efficient at communicating—we have to make explicit what was once tacit. Our talk becomes pedestrian and pedantic, mechanical rather than allusive. We lose the superpower of description.

# [Rails 4 Engines](http://tech.taskrabbit.com/blog/2014/02/11/rails-4-engines)

We have found that a [single app made up of several Rails engines](https://github.com/taskrabbit/rails_engines_example) strikes a great balance between the (initial) straightforwardness of the single Rails app and the modularity of the more service-oriented architecture.

Things got rough in coordinating across these apps. It wasn’t just the data access. We made APIs and allowed any app to have read-only access to the platform app’s database. This allowed things go much faster by preventing creation of many GET endpoints and possible points of failure. The main issue in coordinating releases that spanned apps. They just went slower than if it was one codebase. There was also interminable bumping of gem versions to get shared code to all the apps. Integration testing the whole experience was also very rough.

A single pull request has everything related to that feature. It rolls out atomically. Gems can be bumped once and our internal gems aren’t bumped at all as they live unbuilt in a gems folder in the app itself. We still get most of the modularization that multiple apps had. For example, the User model in the payments engine has all the stuff about balances and the one in the profile engine doesn’t know anything about all that and it’s various helper methods.

The issue with gem upgrades and odd server configurations does continue to exist in the engine model and is mostly fine in the many app model. The gem one is tough and we just try to stay on top of upgrading to the newest things and overall reducing dependencies. The specs will also run slower in the engine app, but you’ll have better integration testing.

The first engine we’ve recommend making to people is the admin engine. We started treating our hardworking admins like we should: a customer with their own needs and dedicated experience.

We don’t share layouts between our engines. We’ve made the choice to have all the frontend code in one engine and all of the other engines just serve API endpoints. There are several shared mixins for these backend engines, but they don’t need a layout because they are just using jbuilder to send back JSON to the frontend client. The frontend engine, therefore, doesn’t really use any models and has all the assets and such. Admin still has its own layout and uses a more traditional Rails MVC approach.

# [Using foreman and environment variables to isolate and run your apps in development](http://mauricio.github.io/2014/02/09/foreman-and-environment-variables.html)

```
rails: bundle exec rails s
postgres: postgres -D /Users/mauricio/databases/postgresql
elasticsearch: elasticsearch -f
```

```
alias fs="foreman start"
```

And foreman automatically loads the `.env` file that is at the same directory as your `Procfile`.

# [Installing and Building Docker With Ansible](http://blog.ansibleworks.com/2014/02/12/installing-and-building-docker-with-ansible)

```
ansible-galaxy install angstwad.docker_ubuntu
```

Use ansible-playbook inside a Docker file so we can write our complex automation in Ansible rather than a hodgepodge of docker commands and shell scripts.

```
FROM ubuntu
RUN apt-get -y update
RUN apt-get install -y python-yaml python-jinja2 git
RUN git clone http://github.com/ansible/ansible.git /tmp/ansible
WORKDIR /tmp/ansible
ENV PATH /tmp/ansible/bin:/sbin:/usr/sbin:/usr/bin
ENV ANSIBLE_LIBRARY /tmp/ansible/library
ENV PYTHONPATH /tmp/ansible/lib:$PYTHON_PATH
RUN git clone http://github.com/yourusername/yourrepo.git /tmp/example
ADD inventory /etc/ansible/hosts
WORKDIR /tmp/examples
RUN ansible-playbook site.yml -c local
EXPOSE 22 3000
ENTRYPOINT [“/usr/bin/foo”]
```

# [Ansible Vault allows keeping encrypted data in Playbooks](http://blog.ansibleworks.com/2014/02/19/ansible-vault/)

```
ansible-vault create vars.yml
ansible-vault edit vars.yml
ansible-playbook site.yml --ask-vault-pass
ansible-vault rekey vars.yml # change password
ansible-vault decrypt vars.yml # permanently decrypt
ansible-vault [encrypt|decrypt|rekey] vars1.yml vars2.yml vars3.yml
```

# [Ansible 1.5 Released](http://blog.ansibleworks.com/2014/02/28/ansible-1-5-released)

* Vault - a method of encrypting data in playbooks
* SSH pipelining
* implicit localhost
* play_hosts
* docker_image

# [postmodern/ruby-install](https://github.com/postmodern/ruby-install)

Does not require updating every time a new Ruby version comes out.
Does not require recipes for each individual Ruby version or configuration.
Does not support installing trunk/HEAD.

# [AdequateRecord Pro™: Like ActiveRecord, but more adequate](http://tenderlovemaking.com/2014/02/19/adequaterecord-pro-like-activerecord.html)

AdequateRecord Pro™ is a fork of ActiveRecord with some performance enhancements. In this post, I want to talk about how we achieved high performance in this branch. I hope you find these speed improvements to be “adequate”.

# [Gold Master Testing](http://blog.codeclimate.com/blog/2014/02/20/gold-master-testing/)

Rather than trying to specify all of the logical paths through an untested module, you can feed it a varied set of inputs and turn the outputs into automatically verifying tests. There’s no guarantee the outputs are correct in this case, but at least you can be sure they don’t change (which, in some systems is even more important).

1. Choose (or randomly generate, using a known seed) a set of inputs for your module or program.
2. Run the inputs through a known-good version of the system, persisting the output.
3. When testing a change, run the same inputs through the new version of the system and flag any output variation.
4. For each variation, have a human determine whether or not the change is expected and desirable. If it is, update the persisted gold master records.

# [The risks of feature branches and pre-merge code review](http://thepugautomatic.com/2014/02/code-review/)

Continuous delivery is about constantly deploying your code, facilitated by a pipeline: if some series of tests pass, the code is good to go. Ideally it deploys production automatically at the end of this pipeline.

Cycles are short and features are often released incrementally, perhaps using feature toggles.

This has major benefits. But if something clogs that pipeline, the benefits are reduced. And pre-merge code review clogs that pipeline.

> I always think that the longer a branch exists then the more work you are producing just to keep things integrated.

# [bbatsov/ruby-style-guide](https://github.com/bbatsov/ruby-style-guide)

# [Ruby Dependency Injection](http://theaudaciouscodeexperiment.com/blog/2013/10/18/ruby-dependency-injection/)

* Treat instantiating collaborators as a separate concern
* Remove this concern from your application’s core
* Pass in the instantiated object(s)

The key to getting the most out of DI is that all of your objects are instantiated for you somewhere else in the system. Objects can then concentrate on doing what they do rather than who they do it with and what their dependencies might be.

# [all the little things (rubyonales)](https://speakerdeck.com/skmetz/all-the-little-things-rubyonales)

Want better apps - make smaller things

Duplication is far cheaper than the wrong abstraction

Reach for open/closed

Small methods are simple

Small objects are simple

# [HM9000: Ready for Launch](http://blog.cloudfoundry.com/2014/02/22/hm9000-ready-for-launch/)

Cloud Foundry (CF) is a platform-as-a-service that, once deployed, makes it easy for developers to deploy, run and scale web applications. Powering this elegant PAAS is a complex distributed system comprised of several inter-operating components: the Cloud Controller (CC) accepts user input and directs Droplet Execution Agents (DEAs) to stage and run web applications. Meanwhile, the Router maps inbound traffic to web-app instances, while the Loggregator streams log output back to developers. All these components communicate via NATS, a performant message bus.

In terms of our simple mental model, HM’s job is easy to express:

* collect the desired state of the world (from the CC via HTTP)
* collect the actual state (from the DEAs via application heartbeats over NATS)
* perform a set diff to find discrepancies – e.g. missing apps or extra (rogue) apps
* send START and STOP messages to resolve these discrepancies

HM9000 solves the high-availability problem by relying on [etcd](https://github.com/coreos/etcd), a robust high-availability store distributed across multiple nodes. Individual HM9000 components are built to rely completely on the store for their knowledge of the world. This removes the need for maintaining in-memory information and allows clarifies the relationship between the various components (all data must flow through the store).

To avoid the singleton problem, we will turn on multiple instances of each HM9000 component across multiple nodes. These instances will vie for a lock in the high-availability store. The instance that grabs the lock gets to run and is responsible for maintaining the lock. Should that instance enter a bad state or die, the lock becomes available allowing another instance to pick up the slack. Since all state is stored in the store, the backup component should be able to function independently of the failed component.

Rather than communicate via messages the HM9000 components coordinate on data in etcd. The component that fetches desired state simply updates the desired state in the store. The component that listens for app heartbeats simply updates the actual state in the store. The analyzer performs the set diff by querying the actual state and desired state and placing decisions in the store. The sender sends START and STOP messages by simply acting on these decisions.

To ensure that HM9000′s various components use the same schema, we built a separate ORM-like library on top of the store. This allows the components to speak in terms of semantic models and abstracts away the details of the persistence layer. In a sense, this library forms the API by which components communicate. Having this separation was crucial – it helped us DRY up our code, and gave us one point of entry to change and version the persisted schema.

The power behind this data-centered approach is that it takes a time-domain problem (listening for heartbeats, polling for desired state, reacting to changes) and turns it into a data problem: instead of thinking in terms of responding to an app’s historical timeline it becomes possible to think in terms of operating on data sets of different configurations. Since keeping track of an app’s historical timeline was the root of much of the complexity of the original HM, this data-centered approach proved to be a great simplification for HM9000.

The mental model of timestamped decisions that are verified by the sender makes the problem domain easier to reason about, and the codebase cleaner. Moreover, it becomes much easier to unit and integration test the behavior of the system as the correct state can be set-up in the store and then evaluated.

Requiring that coordination be done via a data store allows us to build components that have no in-memory knowledge of the world. If a given component fails, another copy of the component can come up and take over its job — everything it needs to do its work is already in the store.

> Each component vies for a lock in etcd and maintains the lock as it does its work. Should the component fail, the lock is released and its doppelgänger can pick up where it left off.

# [Is Angular.js or Ember.js the better choice for Javascript frameworks?](http://www.quora.com/Client-side-MVC/Is-Angular-js-or-Ember-js-the-better-choice-for-Javascript-frameworks)

# [How to build a startup that learns quickly](https://medium.com/frameworks-ftw/fa74545c25a0)

#### If you’re not focused on the speed at which you learn, then you’re doing it wrong

```
revenue = money / time
information = money
revenue = information / time
```

The rate at which you gather information + make decisions serves as a proxy for the speed at which you’ll generate revenue. The faster you learn what works, the faster you’ll make money.

Reduce the amount time between someone on your team wondering how customers will use your product and knowing how they will use it.

[See and hear a 5-minute video of a real person using your site](http://peek.usertesting.com/)

Have every employee connect with customers in personal ways to distribute learning and get all team members thinking about how to solve problems.

# [Smart Guy Productivity Pitfalls](http://bookofhook.blogspot.de/2013/03/smart-guy-productivity-pitfalls.html)

An overinflated sense of your own abilities creates a constant state of production deficit, because you assume that you can make it up with a burst of brilliance and/or crunch.

1. Develop self-awareness
2. Give a shit
3. Minimize uncertainty
4. Commit to getting something done every day
5. Never say "I'll finish it up tomorrow" or "I'll make up for it by coming in early/staying late/working the weekend"
6. Do not overpromise to make up for poor productivity
7. Have an objective productivity metric
8. Accept that "the grind" is part of the job

# [Why Wesabe Lost to Mint](http://blog.precipice.org/why-wesabe-lost-to-mint/)

First, we chose not to work with Yodlee, but failed to find or make a replacement for them (until too late). We had some acquisition interest simply for the aggregator we’d built. We just didn’t build it nearly fast enough. That one mistake (not using or replacing Yodlee before Mint had a chance to launch on Yodlee) was probably enough to kill Wesabe alone.

Mint focused on making the user do almost no work at all, by automatically editing and categorizing their data, reducing the number of fields in their signup form, and giving them immediate gratification as soon as they possibly could; we completely sucked at all of that. Instead, I prioritized trying to build tools that would eventually help people change their financial behavior for the better, which I believed required people to more closely work with and understand their data. My goals may have been (okay, were) noble, but in the end we didn’t help the people I wanted to since the product failed. I was focused on trying to make the usability of editing data as easy and functional as it could be; Mint was focused on making it so you never had to do that at all. Their approach completely kicked our approach’s ass. (To be defensive for just a moment, their data accuracy – how well they automatically edited – was really low, and anyone who looked deeply into their data at Mint, especially in the beginning, was shocked at how inaccurate it was. The point, though, is hardly anyone seems to have looked.)

Not being dependent on a single source provider, preserving users’ privacy, helping users actually make positive change in their financial lives are great, rational reasons to pursue what we pursued. But none of them matter if the product is harder to use, since most people simply won’t care enough or get enough benefit from long-term features if a shorter-term alternative is available.

> A domain name doesn’t win you a market; launching second or fifth or tenth doesn’t lose you a market. You can’t blame your competitors or your board or the lack of or excess of investment.  Focus on what really matters: making users happy with your product as quickly as you can, and helping them as much as you can after that.  If you do those better than anyone else out there you’ll win.

# [colourco.de](http://colourco.de/)

# [CircuitBreaker](http://martinfowler.com/bliki/CircuitBreaker.html)

One of the big differences between in-memory calls and remote calls is that remote calls can fail, or hang without a response until some timeout limit is reached.

You wrap a protected function call in a circuit breaker object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all. Usually you'll also want some kind of monitor alert if the circuit breaker trips.

Since remote calls are often slow, it's often a good idea to put each call on a different thread using a future or promise to handle the results when they come back. By drawing these threads from a thread pool, you can arrange for the circuit to break when the thread pool is exhausted.

A common technique here is to put all requests on a queue, which the supplier consumes at its speed - a useful technique to avoid overloading servers. In this case the circuit breaks when the queue fills up.

[wsargent/circuit_breaker](https://github.com/wsargent/circuit_breaker/tree/master) - CircuitBreaker is a relatively simple Ruby mixin that will wrap a call to a given service in a circuit breaker pattern.

# [Fault Tolerance in a High Volume, Distributed System](http://techblog.netflix.com/2012/02/fault-tolerance-in-high-volume.html)

Some approaches to fallbacks we use are, in order of their impact on the user experience:

* **Cache**: Retrieve data from local or remote caches if the realtime dependency is unavailable, even if the data ends up being stale
* **Eventual Consistency**: Queue writes (such as in SQS) to be persisted once the dependency is available again
* **Stubbed Data**: Revert to default values when personalized options can't be retrieved
* **Empty Response**: Return a null or empty list which UIs can then ignore

# [Running Stripe CTF 2.0 on Mesos](http://karimson.com/posts/ctf-mesos/)

Mesos is a cluster manager that provides resource isolation and sharing across a cluster of machines. It can be thought of as an application scheduler for the data center. My idea was to leverage Mesos for scheduling and managing the levels. The problem is that Mesos provides a fairly low-level interface and does not have an out-of-the-box way of managing long-running applications. Luckily Mesosphere has released a solution in the form of Marathon.

Marathon is a Mesos framework for long-running services, and comes with a great Web UI and a REST interface for launching, scaling, and destroying applications. As soon as a participant needs a new level a request is made to Marathon that then handles the interaction with Mesos and makes sure that the level gets scheduled. Mesosphere has also open-sourced a way for Mesos to launch and interact with Docker.

HAProxy is a robust battle-tested load-balancer/proxy. Using Mesos means that I do not have direct control over which machine is running a particular container so HAProxy is used to redirect the user to the correct container regardless of where it is running.

# [Rails - the Missing Parts - Interactors](http://eng.joingrouper.com/blog/2014/03/03/rails-the-missing-parts-interactors)

The overwhelming trend in Rails codebases is for the majority of business logic to reside in very large God classes in the ActiveRecord /models directory. This is normally a clue that each class has too many responsibilities, a vast public API and methods that require the presence of a complex graph of associated objects in order to function at all.

Interactors demand that the core of your application should live in a set of plain-old-Ruby-objects (POROs) that are responsible for the main use-cases of your application, leaving your ActiveRecord classes as skinny interfaces to your data-store. By looking at the names of your Interactors, you should be able to tell what your application does; SignUp, BookGrouper, AssignBarForGrouper, etc. Classes like Member and Bar just validate and store attributes like name, location and date.

#### [HN](https://news.ycombinator.com/item?id=7335211)

The key point for an "interactor" extraction is when you have multiple models being created in symphony, like a Signup model. Or if you for some reason need to reuse the behavior. But if all your controllers look like this, with one "interactor" model per action, you're doing it wrong.

One way to spend hundreds of thousands of LOC on an application is to stuff it with needless abstractions. That doesn't make it "advanced", and it's not Rails that's falling over, it's probably just some shitty code.

It's certainly a red herring that you need to teach your abstractions to new developers and that it's an endeavor to do so.

Build the abstraction when you actually need it, not when you think you're going to need it, or pretty close to needing it, etc. Because 98% of the time, YAGNI.

# [Microservices](http://martinfowler.com/articles/microservices.html)

Monolith - a single logical executable. Any changes to the system involve building and deploying a new version of the server-side application.

> A component is a unit of software that is independently replaceable and upgradeable.

Libraries are components that are linked into a program and called using in-memory function calls, while services are out-of-process components that communicate with a mechanism such as a web service request, or remote procedure call.

One main reason for using services as components (rather than libraries) is that services are independently deployable.

Remote calls are more expensive than in-process calls, and thus remote APIs need to be coarser-grained, which is often more awkward to use. If you need to change the allocation of responsibilities between components, such movements of behavior are harder to do when you're crossing process boundaries.

Microservice proponents prefer the notion that a team should own a product over its full lifetime. A common inspiration for this is Amazon's notion of "you build, you run it" where a development team takes full responsibility for the software in production. 

The product mentality, ties in with the linkage to business capabilities. Rather than looking at the software as a set of functionality to be completed, there is an on-going relationship where the question is how can software assist its users to enhance the business capability.

> Smart endpoints and dumb pipes

The biggest issue in changing a monolith into microservices lies in changing the communication pattern. A naive conversion from in-memory method calls to RPC leads to chatty communications which don't perform well. Instead you need to replace the fine-graining communication with a coarser-grained approach.

DDD divides a complex domain up into multiple bounded contexts and maps out the relationships between them.

Often businesses handle a degree of inconsistency in order to respond quickly to demand, while having some kind of reversal process to deal with mistakes. The trade-off is worth it as long as the cost of fixing mistakes is less than the cost of lost business under greater consistency.

| Environment | Tests |
|-|-|
| Build | Unit, Functional & Acceptance |
| Integration | Integration tests |
| UAT | User acceptance tests |
| Performance | performance tests |

A consequence of using services as components, is that applications need to be designed so that they can tolerate the failure of services. Microservice teams constantly reflect on how service failures affect the user experience.

Since services can fail at any time, it's important to be able to detect the failures quickly and, if possible, automatically restore service. Microservice applications put a lot of emphasis on real-time monitoring of the application, checking both architectural elements (how many requests per second is the database getting) and business relevant metrics (such as how many orders per minute are received).

Microservice teams would expect to see sophisticated monitoring and logging setups for each individual service such as dashboards showing up/down status and a variety of operational and business relevant metrics. Details on circuit breaker status, current throughput and latency are other examples we often encounter in the wild.

# [The Best PR Advice You’ve Never Heard](http://firstround.com/article/The-Best-PR-Advice-Youve-Never-Heard-from-Facebooks-Head-of-Tech-Communications)

#### Relevant.

Who is your audience, and is your company solving a problem that they care about? What matters to them about that problem? Why does your solution deserve attention? Fight for greater relevance. Make it a priority in your positioning.

#### Inevitable.

You want people to feel that whatever you’re developing is inevitable. This is like having a gust of wind at your company’s back.  If it doesn’t seem like whatever trend or movement you’re a part of will eventually come to pass, you’ll be fighting against the wind.

#### Believable.

Being believable isn't just convincing people you can win, it's convincing them that they want you to win.

#### Simple.

People are torn in so many directions these days — they’re on Facebook, checking email, trying to balance work and friends and family. Somehow you have to break through, and the way to do this is to keep things simple.

> What is the one line you want people to remember? You only get one.

You need that long-term vision that inspires people. But if you don’t make things happen in the short-term, no one is going to care.

> Launching is like the opening move in a chess game. It doesn't mean that much.

You should only launch if you already know what your second move is going to be. This is a journey, and you need to be continuously putting points on the board. To do that, you have to know where you’re going next. This is what will elevate whatever you’re doing in the short term to the next level. And the more short-term points you rack up, the more believable the long-term message becomes.

You have such limited resources at the beginning and everyone is telling you that you have to do different things. What really belongs at the top of your list?

#### Brand lens

```
In Action
    Differentiators
       Attributes
            Tagline
```

**TAGLINE**: for Google, it’s to organize all of the world’s information. For Facebook, it’s giving people the power to share and make the world more open and connected.

**ATTRIBUTES**: at Google, one of the key adjectives seems to be “fun” — easily observed in the colorful, whimsical feel of its offices. At Facebook, it's moving fast, constantly evolving.

**DIFFERENTIATORS**: these are the things that set you apart from the other companies out there in the space.

**ACTION**: whatever it is you think you want to do, run it through your brand lens. See if it highlights the words that you’ve chosen that are meaningful to you and that set you apart. If the answer is no, don’t do it. If the answer is yes, then you have to do it.

Taking action is also about separating internal priorities from external priorities. Inside the company, people are working on a lot of diverse projects, but not everything deserves the spotlight.

> Focus your external marketing on where you want to go as a company, where you have to go to succeed, or what inspires your customers most. It might not be what you are building today.

Figure out who you are as a founder, as a leader, as a brand. And whatever you are, be the best at it.

Don’t try to be all things to all people. It’s ugly and impossible.

A lot of money can make you very stupid — especially early on. A lot of attention can make you stupid. It can make you do a lot of things that aren’t the right things. Focus on what you need to do, not just what you can do because you have the resources.

Don’t be lazy. Don’t launch at a conference. You can use conferences to continue to get your product out there and talk about it, but actually launching at one is pure laziness. Don’t use buzzwords. People don’t read them. They sound like white noise.

Don’t get into fights with people or other brands.

The more you keep your eyes fixed on competitors, the less you’re doing to build your own company.

You are never as good or as bad as the press says you are, so don’t buy into it too much.

As a founder, you know more about your topic than anyone in the world.

The best CEOs I have ever worked for are tremendous listeners. Take everything as a listening opportunity.

Be very conscious of the company you keep

You know you have deeply resonant messaging when it only gains meaning as time passes. Make sure as weeks and years pass, your message is only getting sharper, clearer, more impactful.

# [Coconut Headphones: Why Agile Has Failed](http://mikehadlow.blogspot.co.uk/2014/03/coconut-headphones-why-agile-has-failed.html)

Because creating good software is so much about technical decisions and so little about management process, I believe that there is very little place for non-technical managers in any software development organisation. If your role is simply asking for estimates and enforcing the agile rituals: stand-ups, fortnightly sprints, retrospectives; then you are an impediment rather than an asset to delivery.

* The skills and talents of individual programmers are the main determinant of software quality. No amount of management, methodology, or high-level architecture astronautism can compensate for a poor quality team.
* The motivation and empowerment of programmers has a direct and strong relationship to the quality of  the software.
* Hard deadlines, especially micro-deadlines will result in poor quality software that will take longer to deliver.
* The consequences of poor design decisions multiply rapidly.
* It will usually take multiple attempts to arrive at a viable design.
* You should make it easy to throw away code and start again.
* Latency kills. Short feedback loops to measurable outcomes create good software.
* Estimates are guess-timates; they are mostly useless. There is a geometric relationship between the length of an estimate and its inaccuracy.
* Software does not scale. Software teams do not scale.
* Architecture should be as much about enabling small teams to work on small components as the technical requirements of the software.

# [Ansible provisioning of a Galera Cluster (Percona XtraDB Cluster)](http://patg.net/docker/2014/03/03/ansible.html)

# [Dockerfile Best Practices - take 2](http://crosbymichael.com/dockerfile-best-practices-take-2.html)

#### Don't boot init

The goal is that you only run one process per container so an init or supervisor is not needed. You don't need the added overhead of init or a supervisor. if the processes dies inside a container then the container dies, instead of restarting the process just restart the same container or a new container.

#### Don't upgrade in builds

Best case you run an upgrade in a build and it works. Worst case a pkg tries to mount, etc and it fails. You should bake security fixes into the base images and rebuild on top of them so that the end result is consistent.

3. Use small base images (eg `debian:jessie`)
4. Use specific tags
5. Group common operations
6. Use your own base images

# [The Relationship Between Hours Worked and Productivity](http://cs.stanford.edu/people/eroberts/cs201/projects/crunchmode/econ-hours-productivity.html)

This effectively means that productivity during 60 hour weeks would be less than two-thirds that of what it was when 40 hour weeks were worked.

Thus, overworked employees may simply be substantially less productive at all hours of the work day, enough so that their average productivity decreases to the extent the additional hours they are working provide no benefit (and, in fact, are detrimental). Sleep deprivation and sustained reduced sleep is known to negatively impact productivity at all hours of the day.

[Confessions of an Intermediate Programmer](http://www.michaelbromley.co.uk/blog/65/confessions-of-an-intermediate-programmer)

... these functions were scattered all over the place; because I had no real way of knowing if I was going to break something in some subtle way; because the code was inconsistent and I’d have to carefully study how each instance slightly differed from the last; because much of the code was tightly coupled with other parts which might also subtly break when I made changes. In short, it was going to be tough because of all the bad practices and lack of understanding that had informed the creation of this sprawling mess that only now revealed itself to me.

I learned first-hand – and painfully – why there is a right way and a wrong way to do things. It’s not just a matter of taste or fad. It’s not a matter of who has the cleverest arguments. The right way has real-world ramifications which will make your life (and the lives of others who touch your code) better. The wrong way leads to frustration and wasted time.

> It's no sin to be a beginner or an intermediate. It’s no sin to be a competent programmer instead of a leader. The sin is in how long you remain a beginner or an intermediate after you know what you have to do to improve. **Steve McConnell**

#### [HN](https://news.ycombinator.com/item?id=7337278)

I write and rewrite more now. I view the first time the code works as just the first draft (like I would with a paper). Earlier in my career I thought that making it work meant I was done.

I spend a lot more time thinking about what's happening in the code and why. I have found some of my best work to happen after days of thinking about small bits of functionality.

While I'm more tolerant, I'm less distracted. When I was younger, I spent more time switching technologies to learn "new things". Now I spend more time going deeper on my current stack to learn new things.

I now think its ok to write code in a "non optimal" way if it makes it easier for the entire team to work with. I don't believe in writing to the LCD, however I do believe programming just a little above the team's moving average capability is probably better than writing above everyone's head (whether by me or someone better than me).

> Engineer the small pieces well, and the big pieces will take care of themselves.

90% of the time SQL is a better solution. You don't fully realize all the great stuff a real SQL engine does for you until you have to go without it.

Know when you are in prototype mode, pitch/demo mode, quick script mode, or Serious engineering mode. Each call for different approaches, and have different requirements. Don't let the Serious engineer get you to do a 10 day development cycle when you have a time limit of 1 day to deliver. That's a fail. Also, it's a fail if you hack something up without following all the development guidelines for some embedded life critical piece of software.

> The naming thing is huge. Give things good names. One can also factor out some specialized code into its own method / class - but because you want to re-use it necessarily but because you want to describe what it is doing. Divide et impera.

Having to explain to another what you're doing - I found that to be great as well. It removes bugs and produces cleaner code. You don't even need another - at check-in time, for every change, you can ask yourself "what is this doing" and "why". And if the answer isn't convincing, change what you're doing.

# [Personal Challenges of Working Remotely](http://www.paperplanes.de/2014/2/14/personal-challenges-of-remote-work.html)

The best part about working from home is that there are no distractions. We have a lot more room, compared to an office, to get work done. As attention-seeking humans, we tend to look for distractions if we don't have any. When you're alone at home, you look for contact with other people.

I've started forcing myself to not open email before noon. I tend to be the most creative in the morning hours, and with the team slowly waking up throughout the day, the amount of other distractions increases too. I've stopped reading emails on weekends too. I found my weekends much more relaxing since then.

For being in a creative workline, we have a curious tendency of actively looking for distractions where we could put the energy to much better use.

> Create before consuming

Takes a few minutes in the morning to think about what I want to get done, but taking that time to think about it already gives you the feeling of having goals.

Being able to cross them off a list with a physical activity, like violently striking through the tasks, can be rewarding.

At the end of the day, you'll have a list of tasks you got done.

If you didn't get one of them done, maybe it needs to be broken down into smaller steps?

> Big tasks kill productivity, as they appear to never be fully done.

When you don't focus on anything else, your mind can regenerate.

# [Why You Should Charge For Your Beta Product](http://www.paperplanes.de/2014/2/18/why-you-should-charge-for-your-beta-product.html)

Free customers don't validate a business, they don't validate a product. Only when customers are willing to open their wallet for your product will you start to have validation that you might be on to something.

Offering a product for free while it's in beta implies the assumption that the product doesn't provide any value while it's in beta. If your product doesn't provide any value while it's in beta, stop what you're working on right now.

The best way to validate a product is to get a customer to pay for it, then 10 customers, 100 customers.

# [Building an Infrastructure Service on Top of Infrastructure Services](http://www.paperplanes.de/2014/2/26/building-an-infrastructure-service.html)

Most of the code runs on Heroku, our RabbitMQ is hosted by CloudAMQP, our database is run by Heroku Postgres, our build servers are managed by Blue Box, our logs go into Papertrail, our metrics to Librato, our alerts come from OpsGenie, our status page is hosted on StatusPage.io, even our Chef server, the one bit that we use to customize some of our servers, is hosted.

Other people may be able to do this a lot better than you. They help you free up time to work on things that are relevant to your products and your customers.

> Your time is very valuable. It's more valuable spent on your own product rather than build other things around it.

Both our PostgreSQL database and our RabbitMQ setup are critical parts of Travis CI. Without the database, we can't store or read any data. Without our message queue, we can't push build logs and build jobs through the system, effectively leaving the system unable to run any tests for our customers.

We encrypt SSH keys and OAuth tokens, the most private data that's entrusted to our systems. Of course, the keys aren't stored in the database.

We started out small, with just a few Heroku dynos and a small database setup, a shared RabbitMQ setup to boot.

In fact, initially Travis CI ran on just one dyno, then two, then just a few more when a second application was split out.

I was sceptical at first whether we can scale up while remaining on managed infrastructure rather than build our own. Almost two years later, it's still working quite well.

# [Rails - the Missing Parts - Policies](http://eng.joingrouper.com/blog/2014/03/20/rails-the-missing-parts-policies/)

The seasoned Ruby developer should reach for a plain-old Ruby object that implements a very narrow public API. For the sake of common language, we call these objects “Policies” – they’re similar in many ways to Interactors, but are concerned with complex read operations, rather than writing new data.

[tomblomfield/policy](https://github.com/tomblomfield/policy) Simple implementation of Policies in Ruby - an object-oriented approach to controller permissioning.

These Policy objects aren’t always the right solution - if you’ve only got one of two simple permission checks that are run on a single controller, stick them directly in a before\_filter. But when you find yourself copy-pasting code changes between controller and struggling with unwieldy multi-line before_filters, Policies provide a useful addition.

# [Useful Docker Bash functions and aliases](http://www.kartar.net/2014/03/some-useful-docker-bash-functions-and-aliases/)

```
alias dip="docker inspect --format '{{ .NetworkSettings.IPAddress }}'"

alias did="docker inspect --format '{{ .ID }}'"

alias dkd="docker run -d -P"

alias dki="docker run -t -i -P"

drm() { docker rm $(docker ps -q -a); }

dri() { docker rmi $(docker images -q); }

db() { docker build -t="$1" .; }
```

# [Notes on Distributed Systems for Young Bloods](http://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/)

Since distributed systems require more machines and more capital, their engineers tend to work with more teams and larger organizations. The social stuff is usually the hardest part of any software developer’s job, and, perhaps, especially so with distributed systems development.

#### Distributed systems are different because they fail often

What sets distributed systems engineering apart is the probability of failure and, worse, the probability of partial failure.

One of the writes may succeed while the other fails, and so now how do we get a consistent view of the data? These partial failures are much harder to reason about.

> Design for failure.

#### Writing robust distributed systems costs more than writing robust single-machine systems

Whether it’s because they only occur on dataset sizes much larger than can be fit on a shared machine, or in the network conditions found in datacenters, distributed systems tend to need actual, not simulated, distribution to flush out their bugs.

#### Robust, open source distributed systems are much less common than robust, single-machine systems

#### Coordination is very hard

Avoid coordinating machines wherever possible. This is often described as _horizontal scalability_. The real trick of horizontal scalability is independence – being able to get data to machines such that communication and consensus between those machines is kept to a minimum. Every time two machines have to agree on something, the service is harder to implement.

#### If you can fit your problem in memory, it’s probably trivial

#### _It’s slow_ is the hardest problem you’ll ever debug

#### Implement backpressure throughout your system

Backpressure is the signaling of failure from a serving system to the requesting system and how the requesting system handles those failures to prevent overloading itself and the serving system. Designing for backpressure means bounding resource utilization during times of overload and times of system failure. This is one of the basic building blocks of creating a robust distributed system.

Common versions include dropping new messages on the floor (and incrementing a metric) if the system’s resources are already over-scheduled, and shipping errors back to users when the system determines it will be unable to finish the request in a given amount of time. Timeouts and exponential back-offs on connections and requests to other systems are also useful.

#### Find ways to be partially available

A typical search system sets a time limit on how long it will search its documents, and, if that time limit expires before all of its documents are searched, it will return whatever results it has gathered.

#### Metrics are the only way to get your job done

#### Use percentiles, not averages

Percentiles (50th, 99th, 99.9th, 99.99th) are more accurate and informative than averages in the vast majority of distributed systems.

_Average latency_ is a commonly reported metric, but I’ve never once seen a distributed system whose latency followed a bell curve. If the metric doesn’t follow a bell curve, the average is meaningless and leads to incorrect decisions and understanding.

#### Learn to estimate your capacity

Knowing how many machines you need to perform a task is the difference between a long-lasting system, and one that needs to be replaced 3 months into its job.

How many tweet ids can you fit in memory on a common machine? Well, a typical machine at the end of 2012 has 24 GB of memory, you’ll need an overhead of 4-5 GB for the OS, another couple, at least, to handle requests, and a tweet id is 8 bytes. This is the kind of back of the envelope calculation you’ll find yourself doing.

#### Feature flags are how infrastructure is rolled out

Suppose you’re going from a single database to a service that hides the details of a new storage solution. Have the service wrap around the legacy storage, and ramp up writes to it slowly. With backfilling, comparison checks on read (another feature flag), and then slow ramp up of reads (yet another flag), you will have much more confidence and fewer disasters. Too many projects have failed because they went for the “big cutover” or a series of “big cutovers” that were then forced into rollbacks by bugs found too late.

Feature flags sound like a terrible mess of conditionals to a classically trained object-oriented developer or a new engineer with well-intentioned training. And the use of feature flags means accepting that having multiple versions of infrastructure and data is a norm, not an rarity.

Feature flags are best understood as a trade-off, trading local complexity (in the code, in one system) for global simplicity and resilience.

#### Choose id spaces wisely

#### Exploit data-locality

The closer the processing and caching of your data is kept to its persistent storage, the more efficient your processing, and the easier it will be to keep your caching consistent and fast.

If multiple users are making the same expensive request at nearly the same time, perhaps their requests can be joined into one. If multiple instances of requests for the same kind of data are made near to one another, they could be joined into one larger request. Doing so often affords lower communication overheard and easier fault management.

#### Writing cached data back to persistent storage is bad

If the implementers talk about “Russian-doll caching”, you have a large chance of hitting highly visible bugs.

#### Computers can do more than you think they can

Greater performance is not hard to come by, especially if you are willing to profile your application and introduce efficiencies based on your measurements.

#### Use the CAP theorem to critique systems

However, it is well-suited for critiquing a distributed system design, and understanding what trade-offs need to be made. Taking a system design and iterating through the constraints CAP puts on its subsystems will leave you with a better design at the end. For homework, apply the CAP theorem’s constraints to a real world implementation of Russian-doll caching.

#### Extract services

The coordination costs of using a service is much lower than a shared library when there are multiple client systems. Upgrading a library, even with no API changes needed, requires coordinating deploys of each client system.

Upgrading a library also has a higher social coordination cost than deploying a service if the client systems have different maintainers.

# [How We Make Trello](http://blog.fogcreek.com/how-we-make-trello/)

One stable API, many clients.

There are three channels of the Trello website: “Stable”, “Beta”, and “Alpha”. When you go to trello.com, the server figures out which channel you are on and which version you should see. Everyone is on “Stable”, a handful of folks, maybe 20, have access to the “Beta” channel, and Trello team members and Fog Creekers are on “Alpha”. If you have access to more than one channel, you get a coveted channel switcher.

We iterate and refine until it’s ready for the beta channel. The beta version has a prominent “Give us feedback” button and disclaimer saying this is an early “explorer” versions of Trello and says “look out for these new things”. Then we get feedback, iterate, refine… When we’re almost happy, we slowly roll it out to a small, randomly-selected percentage of people on the stable channel. That usually starts at 1% goes up to 15% over a few days. Then we get plenty of feedback. We look for the big things that come up frequently, then iterate and iterate some more. Now things are great and it goes out to 100% of stable. We draft up a blog post with the biggest, coolest new features & announce it.

Support, internal frustrations & one-on-one sessions. We also do numerous internal polls and hallway usability tests. We also look at anonymous usage tracking in Google Analytics to see what features people are actually using. In all, we hope to get a sense of how people are currently using Trello, how they might want something to work, what they aren’t using, and where their pain points are.

On the back of each card, we take this info into account and propose a few solutions. When we settle on a card that really needs fixing, I’ll take the card, make a few pen and paper sketches based off the proposed solutions, and create a few low-fi mockups and workflows in Sketch.

I try and post workflows and screenshots to the associated Trello card throughout the process so I can get continuous feedback from the team. I know the design is going to change a lot so I don’t waste time with high-fidelity mockups. We can quickly iterate in code anyway.

# [L2TP with IPSec on Mikrotik RoutersOS](http://www.nasa-security.net/mikrotik/mikrotik-l2tp-with-ipsec/)

# [Sandi Metz - Magic Tricks of Testing - Ancient City Ruby 2013](https://www.youtube.com/watch?v=qPfQM4w4I04)

#### Incoming Messages

Test incoming query messaages by making assertions about what they send back.

Test the interface, not the implementation.

Test incoming command messages by making assertions about direct public side effects.

Receiver of incoming message has sole responsibility for asserting the result & direct public side effects.

#### Messages to self

Don't make assertions about their result. Do not expect to send them. You're adding over-specification, cost, but no value. No other object knows about the existence of these methods.

When it comes to complicated algos, use them early on, but discard them when the implementation is done. Or put a comment: "delete these if they fail".

#### Outgoing Messages

Do not test outgoing query messages. Do not make assertions about their result. Do not expect to send them. Over-specification, adds no safety yet breaks every time the implementation changes. Outgoing query messages have no visible side-effects.

When dealing with outgoing command messages, use mocks. Otherwise you are testing distant side-effects - integration testing. Depend on the interface, not the implementation. Test message sending to collaborators responsibilities.

Expect to send outgoing command messages. Breaking this rule can save money if side effects are both stable and cheap.

Stubs define context. Stub as needed, but too many is a smell, as are stubs inside stubs. Avoid stubbing in the object under test. Do not make assertions about stubs. You will end up testing your tests before you know it.

Mocks test behaviour. Set expectations on mocks to test outgoing command messages. One expectation per test (do your best!). Do not stub using mocks.

> Strive for Thorough, Stable, Fast, Few. Test everything once. Test the interface, not the implementation.

# [Ben Orenstein - Live Coding with Ben - Ancient City Ruby 2013](https://www.youtube.com/watch?v=C0H-LyZy9Ko)

Don't encode the structure of the app in your code.

Don't duplicate - not even once - because:

* it's easy to miss the initial duplication
* pull requests don't show duplication

Prefer to not use `let` or `subject` (mystery guests), or `its`. Build everything a test needs inside itself.

> Open/Closed Principle - change the behaviour of a class by injecting a different dependency.

Open/Closed for tests.

Really good code comes out of really good habits.

* avoid things that are tricky
* short red-green cycles
* never refactor during red
* refactor in smaller steps - make sure you can stop at any time
* throwing away refactoring is OK - easier to do if they're small
* commit often

# [The Vast and Endless Sea](http://blog.codinghorror.com/the-vast-and-endless-sea/)

If you want to build a ship, don't drum up the men to gather wood, divide the work and give orders. Instead, teach them to yearn for the vast and endless sea.