# [Lita is a chat bot written in Ruby](http://www.lita.io/)

Lita is a chat bot written in Ruby with persistent storage provided by Redis. It uses a plugin system to connect to different chat services and to provide new behavior. The plugin system uses the familiar tools of the Ruby ecosystem: RubyGems and Bundler.

# [WebSockets in Ruby](http://www.troikatech.com/blog/2014/02/26/websocket-webmachine)

```
App = Webmachine::Application do |app|
  app.configure do |config|
    config.adapter = :Reel
    config.adapter_options[:websocket_handler] = proc do |websocket|
      websocket << "hello, world"
    end
  end
end
```

```
class WebsocketHandler
  def call(websocket)
    loop do
      message = websocket.read
      # do something with the message, call methods on other objects, log stuff, have your fun
    end
  end
end
```

[webmachine-ruby](https://github.com/seancribbs/webmachine-ruby) makes it easy by allowing you to implement streaming APIs without much trouble, and I suppose it’ll only take a bit of JS to fallback from one to the other and provide an abstract connection to consumers.

# [Ruby Gotchas that will come back to haunt you](http://blog.elpassion.com/ruby-gotchas)

#### Use only `&&` / `||` operators

`and` / `or` operators have lower precedence than `&&` / `||`
`and` / `or` have lower precedence than `=`, while `&&` / `||` are of higher precedence
`and` / `or` have the same precedence, while `&&` has higher precedence than `||`

```
(surprise = true) and false # => surprise is true
surprise = (true && false)  # => surprise is false
```

#### Use only `==` operator

`==` / `===` / `eql?` / `equal?` are all different operators, meant for different situations.

#### Use `super` (no parantheses)

#### Inherit from `StandardError` (not Exception)

When you leave rescue statement empty, it means it will catch exceptions that inherit from StandardError, not Exception.

When you rescue Exception (which you should not), you’ll catch errors you won’t be able to recover from (like out of memory error). Also, you’ll catch system signals like SIGTERM, and in effect you won’t be able to terminate your script using CTRL-C.

#### Always use longer, more verbose version with classes wrapped by modules

`module` keyword (as well as `class` and `def`) will create new lexical scope for all the things you put inside.

`module Foo` creates the scope 'Foo', `class Bar`h creates new lexical scope (named 'Foo::Bar'), which has access to its parent scope ('Foo') and all constants declared in it.

`class Foo::Bar` creates another lexical scope, which is also named 'Foo::Bar', but here, it has no parent, and thus, no access to things from 'Foo' scope.

#### Never depend on built-in bang! methods return value

#### `attribute=(value)` always returns passed value

#### `private` will NOT make `self.method` private

You want `private_class_method :method_name` or `class << self`

# [Use An Ask, Don’t Tell Policy With Ruby](http://patshaughnessy.net/2014/2/10/use-an-ask-dont-tell-policy-with-ruby)

Naming methods is one of the most difficult and important things a programmer does. Picking a name for a method gives the reader a hint about what the method does, about what your intentions were when you wrote it.

Don’t imagine you are the computer. Don’t think about how to solve a problem by figuring out what Ruby should do and then writing down instructions for it to follow. Instead, start by asking Ruby for the answer.

> Objects encapsulate state. Don’t break that encapsulation.

When you send a message to an object, you should ask it for what you want, not tell it what to do or make assumptions about how it works internally.

# [Telling, Asking, and the Power of Jargon](http://pragdave.me/blog/2014/02/11/telling-asking-and-the-power-of-jargon/)

The idea of **Tell, Don’t Ask**, is that objects should take responsibility for their state, and should not allow other objects to bypass encapsulation and mess with the state.

Functional programming is about expressions. It’s about composition. It’s about transforming data, not storing it.

When programmers talk to programmers, they use jargon. By using jargon words (or terms of the trade, as the fancy folk call them), we communicate efficiently and effectively—we interact at a much deeper level. Each piece of jargon is a shortcut for a whole lot of shared experience, and by using jargon words, we root our conversation at a deeper level.

But jargon has to be protected. Consistently misuse a jargon word, and it loses its deeper meaning. It it no longer evocative—it’s just a noise. And if our jargon becomes diluted, then we as an industry become less efficient at communicating—we have to make explicit what was once tacit. Our talk becomes pedestrian and pedantic, mechanical rather than allusive. We lose the superpower of description.

# [Rails 4 Engines](http://tech.taskrabbit.com/blog/2014/02/11/rails-4-engines)

We have found that a [single app made up of several Rails engines](https://github.com/taskrabbit/rails_engines_example) strikes a great balance between the (initial) straightforwardness of the single Rails app and the modularity of the more service-oriented architecture.

Things got rough in coordinating across these apps. It wasn’t just the data access. We made APIs and allowed any app to have read-only access to the platform app’s database. This allowed things go much faster by preventing creation of many GET endpoints and possible points of failure. The main issue in coordinating releases that spanned apps. They just went slower than if it was one codebase. There was also interminable bumping of gem versions to get shared code to all the apps. Integration testing the whole experience was also very rough.

A single pull request has everything related to that feature. It rolls out atomically. Gems can be bumped once and our internal gems aren’t bumped at all as they live unbuilt in a gems folder in the app itself. We still get most of the modularization that multiple apps had. For example, the User model in the payments engine has all the stuff about balances and the one in the profile engine doesn’t know anything about all that and it’s various helper methods.

The issue with gem upgrades and odd server configurations does continue to exist in the engine model and is mostly fine in the many app model. The gem one is tough and we just try to stay on top of upgrading to the newest things and overall reducing dependencies. The specs will also run slower in the engine app, but you’ll have better integration testing.

The first engine we’ve recommend making to people is the admin engine. We started treating our hardworking admins like we should: a customer with their own needs and dedicated experience.

We don’t share layouts between our engines. We’ve made the choice to have all the frontend code in one engine and all of the other engines just serve API endpoints. There are several shared mixins for these backend engines, but they don’t need a layout because they are just using jbuilder to send back JSON to the frontend client. The frontend engine, therefore, doesn’t really use any models and has all the assets and such. Admin still has its own layout and uses a more traditional Rails MVC approach.

# [Using foreman and environment variables to isolate and run your apps in development](http://mauricio.github.io/2014/02/09/foreman-and-environment-variables.html)

```
rails: bundle exec rails s
postgres: postgres -D /Users/mauricio/databases/postgresql
elasticsearch: elasticsearch -f
```

```
alias fs="foreman start"
```

And foreman automatically loads the `.env` file that is at the same directory as your `Procfile`.

# [Installing and Building Docker With Ansible](http://blog.ansibleworks.com/2014/02/12/installing-and-building-docker-with-ansible)

```
ansible-galaxy install angstwad.docker_ubuntu
```

Use ansible-playbook inside a Docker file so we can write our complex automation in Ansible rather than a hodgepodge of docker commands and shell scripts.

```
FROM ubuntu
RUN apt-get -y update
RUN apt-get install -y python-yaml python-jinja2 git
RUN git clone http://github.com/ansible/ansible.git /tmp/ansible
WORKDIR /tmp/ansible
ENV PATH /tmp/ansible/bin:/sbin:/usr/sbin:/usr/bin
ENV ANSIBLE_LIBRARY /tmp/ansible/library
ENV PYTHONPATH /tmp/ansible/lib:$PYTHON_PATH
RUN git clone http://github.com/yourusername/yourrepo.git /tmp/example
ADD inventory /etc/ansible/hosts
WORKDIR /tmp/examples
RUN ansible-playbook site.yml -c local
EXPOSE 22 3000
ENTRYPOINT [“/usr/bin/foo”]
```

# [Ansible Vault allows keeping encrypted data in Playbooks](http://blog.ansibleworks.com/2014/02/19/ansible-vault/)

```
ansible-vault create vars.yml
ansible-vault edit vars.yml
ansible-playbook site.yml --ask-vault-pass
ansible-vault rekey vars.yml # change password
ansible-vault decrypt vars.yml # permanently decrypt
ansible-vault [encrypt|decrypt|rekey] vars1.yml vars2.yml vars3.yml
```

# [Ansible 1.5 Released](http://blog.ansibleworks.com/2014/02/28/ansible-1-5-released)

* Vault - a method of encrypting data in playbooks
* SSH pipelining
* implicit localhost
* play_hosts
* docker_image

# [postmodern/ruby-install](https://github.com/postmodern/ruby-install)

Does not require updating every time a new Ruby version comes out.
Does not require recipes for each individual Ruby version or configuration.
Does not support installing trunk/HEAD.

# [AdequateRecord Pro™: Like ActiveRecord, but more adequate](http://tenderlovemaking.com/2014/02/19/adequaterecord-pro-like-activerecord.html)

AdequateRecord Pro™ is a fork of ActiveRecord with some performance enhancements. In this post, I want to talk about how we achieved high performance in this branch. I hope you find these speed improvements to be “adequate”.

# [Gold Master Testing](http://blog.codeclimate.com/blog/2014/02/20/gold-master-testing/)

Rather than trying to specify all of the logical paths through an untested module, you can feed it a varied set of inputs and turn the outputs into automatically verifying tests. There’s no guarantee the outputs are correct in this case, but at least you can be sure they don’t change (which, in some systems is even more important).

1. Choose (or randomly generate, using a known seed) a set of inputs for your module or program.
2. Run the inputs through a known-good version of the system, persisting the output.
3. When testing a change, run the same inputs through the new version of the system and flag any output variation.
4. For each variation, have a human determine whether or not the change is expected and desirable. If it is, update the persisted gold master records.

# [The risks of feature branches and pre-merge code review](http://thepugautomatic.com/2014/02/code-review/)

Continuous delivery is about constantly deploying your code, facilitated by a pipeline: if some series of tests pass, the code is good to go. Ideally it deploys production automatically at the end of this pipeline.

Cycles are short and features are often released incrementally, perhaps using feature toggles.

This has major benefits. But if something clogs that pipeline, the benefits are reduced. And pre-merge code review clogs that pipeline.

> I always think that the longer a branch exists then the more work you are producing just to keep things integrated.

# [bbatsov/ruby-style-guide](https://github.com/bbatsov/ruby-style-guide)

# [Ruby Dependency Injection](http://theaudaciouscodeexperiment.com/blog/2013/10/18/ruby-dependency-injection/)

* Treat instantiating collaborators as a separate concern
* Remove this concern from your application’s core
* Pass in the instantiated object(s)

The key to getting the most out of DI is that all of your objects are instantiated for you somewhere else in the system. Objects can then concentrate on doing what they do rather than who they do it with and what their dependencies might be.

# [HM9000: Ready for Launch](http://blog.cloudfoundry.com/2014/02/22/hm9000-ready-for-launch/)

Cloud Foundry (CF) is a platform-as-a-service that, once deployed, makes it easy for developers to deploy, run and scale web applications. Powering this elegant PAAS is a complex distributed system comprised of several inter-operating components: the Cloud Controller (CC) accepts user input and directs Droplet Execution Agents (DEAs) to stage and run web applications. Meanwhile, the Router maps inbound traffic to web-app instances, while the Loggregator streams log output back to developers. All these components communicate via NATS, a performant message bus.

In terms of our simple mental model, HM’s job is easy to express:

* collect the desired state of the world (from the CC via HTTP)
* collect the actual state (from the DEAs via application heartbeats over NATS)
* perform a set diff to find discrepancies – e.g. missing apps or extra (rogue) apps
* send START and STOP messages to resolve these discrepancies

HM9000 solves the high-availability problem by relying on [etcd](https://github.com/coreos/etcd), a robust high-availability store distributed across multiple nodes. Individual HM9000 components are built to rely completely on the store for their knowledge of the world. This removes the need for maintaining in-memory information and allows clarifies the relationship between the various components (all data must flow through the store).

To avoid the singleton problem, we will turn on multiple instances of each HM9000 component across multiple nodes. These instances will vie for a lock in the high-availability store. The instance that grabs the lock gets to run and is responsible for maintaining the lock. Should that instance enter a bad state or die, the lock becomes available allowing another instance to pick up the slack. Since all state is stored in the store, the backup component should be able to function independently of the failed component.

Rather than communicate via messages the HM9000 components coordinate on data in etcd. The component that fetches desired state simply updates the desired state in the store. The component that listens for app heartbeats simply updates the actual state in the store. The analyzer performs the set diff by querying the actual state and desired state and placing decisions in the store. The sender sends START and STOP messages by simply acting on these decisions.

To ensure that HM9000′s various components use the same schema, we built a separate ORM-like library on top of the store. This allows the components to speak in terms of semantic models and abstracts away the details of the persistence layer. In a sense, this library forms the API by which components communicate. Having this separation was crucial – it helped us DRY up our code, and gave us one point of entry to change and version the persisted schema.

The power behind this data-centered approach is that it takes a time-domain problem (listening for heartbeats, polling for desired state, reacting to changes) and turns it into a data problem: instead of thinking in terms of responding to an app’s historical timeline it becomes possible to think in terms of operating on data sets of different configurations. Since keeping track of an app’s historical timeline was the root of much of the complexity of the original HM, this data-centered approach proved to be a great simplification for HM9000.

The mental model of timestamped decisions that are verified by the sender makes the problem domain easier to reason about, and the codebase cleaner. Moreover, it becomes much easier to unit and integration test the behavior of the system as the correct state can be set-up in the store and then evaluated.

Requiring that coordination be done via a data store allows us to build components that have no in-memory knowledge of the world. If a given component fails, another copy of the component can come up and take over its job — everything it needs to do its work is already in the store.

> Each component vies for a lock in etcd and maintains the lock as it does its work. Should the component fail, the lock is released and its doppelgänger can pick up where it left off.

# [Is Angular.js or Ember.js the better choice for Javascript frameworks?](http://www.quora.com/Client-side-MVC/Is-Angular-js-or-Ember-js-the-better-choice-for-Javascript-frameworks)

# [How to build a startup that learns quickly](https://medium.com/frameworks-ftw/fa74545c25a0)

#### If you’re not focused on the speed at which you learn, then you’re doing it wrong

```
revenue = money / time
information = money
revenue = information / time
```

The rate at which you gather information + make decisions serves as a proxy for the speed at which you’ll generate revenue. The faster you learn what works, the faster you’ll make money.

Reduce the amount time between someone on your team wondering how customers will use your product and knowing how they will use it.

[See and hear a 5-minute video of a real person using your site](http://peek.usertesting.com/)

Have every employee connect with customers in personal ways to distribute learning and get all team members thinking about how to solve problems.